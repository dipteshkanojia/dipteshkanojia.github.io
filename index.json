[{"authors":["admin"],"categories":null,"content":"Researcher working on problems within areas of Natural Language Processing (NLP) and Machine Learning (ML) at the Institute for People-Centred AI (PAI) and School of Computer Science and Electronic Engineering. As a research lead, I manage Human-Machine Interaction @ PAI, and the NLP subgroup within the Nature Inspired Computing and Engineering group (NICE) @ Computer Science Research Centre. I also lead teaching on the NLP module offered to both undergraduate and postgraduate students.\nMy research focuses on developing scalable and safe human-machine interaction using foundation models. Guided by the principles of Responsible and Inclusive AI, my work emphasises cross-lingual and multimodal representation learning to address challenges like online toxicity, misinformation, and digital accessibility for low-resource languages. Our research outcomes- code, data, and models, are publicly available on the SurreyNLP GitHub and HuggingFace.\nMy prior roles include a Postdoctoral Fellowship at the Centre for Translation Studies, a joint PhD from IIT Bombay and Monash University, and Research Engineer at the CFILT Lab.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://dipteshkanojia.co.uk/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Researcher working on problems within areas of Natural Language Processing (NLP) and Machine Learning (ML) at the Institute for People-Centred AI (PAI) and School of Computer Science and Electronic Engineering. As a research lead, I manage Human-Machine Interaction @ PAI, and the NLP subgroup within the Nature Inspired Computing and Engineering group (NICE) @ Computer Science Research Centre. I also lead teaching on the NLP module offered to both undergraduate and postgraduate students.","tags":null,"title":"Diptesh Kanojia","type":"authors"},{"authors":["Diptesh Kanojia"],"categories":["Personal","Photography"],"content":"Apparently, our garden isn\u0026rsquo;t ours anymore; pretty much annexed by this tabby autocrat. He\u0026rsquo;s a neighbour\u0026rsquo;s cat who visits daily as I envy his discipline. Perches on the fence or the shed roof. Of course! he has vantage points for passing judgement.\n I am not impressed!    lower the vantage point, higher the judgement    There\u0026rsquo;s the disgusting human    \u0026lsquo;Why. Peasants. Exist.\u0026rsquo;    \u0026lsquo;where are my treats, servant?\u0026rsquo;    It\u0026rsquo;s frankly embarrassing that you\u0026rsquo;re the one with the opposable thumbs.   Here\u0026rsquo;s the crazy part, given we had pet cats earlier, we feed him cat treats. He comes right inside nowadays through the kitchen window and pretty much demands for food.\nYou\u0026rsquo;d think this would buy some loyalty, or at least a nice purr, right? Nope. Just an excercise in territorial rights and treat tax collection.\nI will update this page further with more disdained looks.\n","date":1761706620,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1761706620,"objectID":"0d6b9273d223245e796b4eac03da1aef","permalink":"https://dipteshkanojia.co.uk/post/tabbyautocrat/","publishdate":"2025-10-29T02:57:00Z","relpermalink":"/post/tabbyautocrat/","section":"post","summary":"Garden has been taken over by this tabby cat who watches my every move with a judgmental side-eye, despite being fed.","tags":["personal","photography","cats","humour","garden"],"title":"The Tabby Autocrat","type":"post"},{"authors":["Archchana Sindhujan","Diptesh Kanojia"],"categories":null,"content":"","date":1761174000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1761174000,"objectID":"9a6d60749b9c40902b3b51a004d43ded","permalink":"https://dipteshkanojia.co.uk/talk/nlpcafe2025-alope/","publishdate":"2025-10-23T00:00:00+01:00","relpermalink":"/talk/nlpcafe2025-alope/","section":"talk","summary":"Large Language Models (LLMs) have shown remarkable performance across a wide range of natural language processing tasks. Quality Estimation (QE) for Machine Translation (MT), which assesses the quality of a source-MT pair without relying on reference translations, remains a challenging cross-lingual task for LLMs. The challenges stem from the inherent limitations of existing LLM-based QE systems, which are pre-trained for causal language modelling rather than regression-specific tasks, further elevated by the presence of low-resource languages given pre-training data distribution. This paper introduces ALOPE, an adaptive layer-optimization framework designed to enhance LLM-based QE by restructuring Transformer representations through layer-wise adaptation for improved regression-based prediction. Our framework integrates low-rank adapters (LoRA) with regression task headers, leveraging select pre-trained Transformer layers for improved cross-lingual alignment. In addition to the layer-specific adaptation, ALOPE introduces two strategies—dynamic weighting, which adaptively combines representations from multiple layers, and multi-head regression, which aggregates regression losses from multiple heads for improved prediction. Our framework shows improvements over various existing LLM-based QE approaches. Empirical evidence suggests that intermediate Transformer layers in LLMs provide contextual representations that are more aligned with the cross-lingual nature of the QE task. Our resultant models and framework code is publicly available for further research, also allowing to scale any existing LLM-based MT frameworks to be equipped with QE capabilities.","tags":["talks","nlp-cafe","quality-estimation","large-language-models","machine-translation"],"title":"ALOPE: Adaptive Layer Optimization for Translation Quality Estimation using Large Language Models","type":"talk"},{"authors":["Archchana Sindhujan","Diptesh Kanojia","Constantin Orăsan"],"categories":null,"content":"","date":1760745600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1760745600,"objectID":"33af91807ddc504c3349649fb7a5c913","permalink":"https://dipteshkanojia.co.uk/publication/sindhujan-etal-2025-reference/","publishdate":"2025-10-18T00:00:00Z","relpermalink":"/publication/sindhujan-etal-2025-reference/","section":"publication","summary":"Reference-less evaluation of machine translation, or Quality Estimation (QE), is vital for low-resource language pairs where high-quality references are often unavailable. In this study, we investigate segment-level QE methods comparing encoder-based models such as MonoTransQuest, CometKiwi, and xCOMET with various decoder-based methods (Tower+, ALOPE, and other instruction-fine-tuned language models). Our work primarily focused on utilizing eight low-resource language pairs, involving both English on the source side and the target side of the translation. Results indicate that while fine-tuned encoder-based models remain strong performers across most low-resource language pairs, decoder-based Large Language Models (LLMs) show clear improvements when adapted through instruction tuning. Importantly, the ALOPE framework further enhances LLM performance beyond standard fine-tuning, demonstrating its effectiveness in narrowing the gap with encoder-based approaches and highlighting its potential as a viable strategy for low-resource QE. In addition, our experiments demonstrates that with adaptation techniques such as LoRA (Low Rank Adapters) and quantization, decoder-based QE models can be trained with competitive GPU memory efficiency, though they generally require substantially more disk space than encoder-based models. Our findings highlight the effectiveness of encoder-based models for low-resource QE and suggest that advances in cross-lingual modeling will be key to improving LLM-based QE in the future.","tags":["quality estimation","machine translation","low-resource languages","LLMs","evaluation"],"title":"Reference-Less Evaluation of Machine Translation: Navigating Through the Resource-Scarce Scenarios","type":"publication"},{"authors":["Archchana Sindhujan","Shenbin Qian","Chan Chi Chun Matthew","Constantin Orăsan","Diptesh Kanojia"],"categories":null,"content":"","date":1759276800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1759276800,"objectID":"71cc6c0db70403b0b6b9ea1629c9bd32","permalink":"https://dipteshkanojia.co.uk/publication/sindhujan-etal-2025-alope/","publishdate":"2025-10-01T00:00:00Z","relpermalink":"/publication/sindhujan-etal-2025-alope/","section":"publication","summary":"Large Language Models (LLMs) have shown remarkable performance across a wide range of natural language processing tasks. Quality Estimation (QE) for Machine Translation (MT), which assesses the quality of a source-target pair without relying on reference translations, remains a challenging cross-lingual task for LLMs. The challenges stem from the inherent limitations of existing LLM-based QE systems, which are pre-trained for causal language modelling rather than regression-specific tasks, further elevated by the presence of low-resource languages given pre-training data distribution. This paper introduces ALOPE, an adaptive layer-optimization framework designed to enhance LLM-based QE by restructuring Transformer representations through layer-wise adaptation for improved regression-based prediction. Our framework integrates low-rank adapters (LoRA) with regression task heads, leveraging selected pre-trained Transformer layers for improved cross-lingual alignment. In addition to the layer-specific adaptation, ALOPE introduces two strategies-dynamic weighting, which adaptively combines representations from multiple layers, and multi-head regression, which aggregates regression losses from multiple heads for QE. Our framework shows improvements over various existing LLM-based QE approaches. Empirical evidence suggests that intermediate Transformer layers in LLMs provide contextual representations that are more aligned with the cross-lingual nature of the QE task. We make resultant models and framework code publicly available for further research, also allowing existing LLM-based MT frameworks to be scaled with QE capabilities.","tags":["quality estimation","machine translation","LLMs","layer optimization","low-resource languages"],"title":"ALOPE: Adaptive Layer Optimization for Translation Quality Estimation using Large Language Models","type":"publication"},{"authors":["Aisha Saeid","Anu Sabu","Girish A Koushik","Ferrante Neri","Diptesh Kanojia"],"categories":null,"content":"","date":1756684800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756684800,"objectID":"ea4adb4ddb4fbcb2044001d38ddc1db3","permalink":"https://dipteshkanojia.co.uk/publication/saeid-etal-2025-cyberbullying/","publishdate":"2025-09-01T00:00:00Z","relpermalink":"/publication/saeid-etal-2025-cyberbullying/","section":"publication","summary":"Detecting cyberbullying on social media remains a critical challenge due to its subtle and varied expressions. This study investigates whether integrating aggression detection as an auxiliary task within a unified training framework can enhance the generalisation and performance of large language models (LLMs) in cyberbullying detection. Experiments are conducted on five aggression datasets and one cyberbullying dataset using instruction-tuned LLMs. We evaluated multiple strategies: zero-shot, few-shot, independent LoRA fine-tuning, and multi-task learning (MTL). Given the inconsistent results of MTL, we propose an enriched prompt pipeline approach in which aggression predictions are embedded into cyberbullying detection prompts to provide contextual augmentation. Preliminary results show that the enriched prompt pipeline consistently outperforms standard LoRA fine-tuning, indicating that aggression-informed context significantly boosts cyberbullying detection. This study highlights the potential of auxiliary tasks, such as aggression detection, to improve the generalisation of LLMs for safety-critical applications on social networks.","tags":["cyberbullying detection","aggression","LLMs","prompting","social media"],"title":"Cyberbullying Detection via Aggression-Enhanced Prompting","type":"publication"},{"authors":["Girish A Koushik","Fatemeh Nazarieh","Katherine Birch","Shenbin Qian","Diptesh Kanojia"],"categories":null,"content":"","date":1756080000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756080000,"objectID":"3eafb750e908fe49ca027e993c45641d","permalink":"https://dipteshkanojia.co.uk/publication/koushik-etal-2025-mind/","publishdate":"2025-08-25T00:00:00Z","relpermalink":"/publication/koushik-etal-2025-mind/","section":"publication","summary":"Visual metaphor generation is a challenging task that aims to generate an image given an input text metaphor. Inherently, it needs language understanding to bind a source concept with a target concept, in a way that preserves meaning while ensuring visual coherence. We propose a self-evaluating visual metaphor generation framework that focuses on metaphor alignment. Our self-evaluation approach combines existing metrics with our newly proposed metaphor decomposition score and a meaning alignment (MA) metric. Within this setup, we explore two novel approaches: a training-free pipeline that explicitly decomposes prompts into source-target-meaning (S-T-M) mapping for image synthesis, and a complementary training-based pipeline that improves alignment using our proposed self-evaluation reward schema, without any large-scale retraining. On the held-out test set, the training-free approach surpasses strong closed baselines (GPT-4o, Imagen) on decomposition, CLIP, and MA scores, with the training-based approach close behind. We evaluate our framework output using a user-facing study, and observed that participants preferred GPT-4o overall, while our training-free pipeline led open-source methods and edged Imagen on abstract metaphors. Our analyses show S-T-M prompting helps longer or more abstract metaphors, with closed models excelling on short, concrete cases; we also observe sensitivity to sampler settings. Overall, structured prompting and lightweight RL perform metaphor alignment well under modest compute, and remaining gaps to human preference appear driven by aesthetics and sampling.","tags":["visual metaphor generation","reward framework","image synthesis","metaphor alignment"],"title":"The Mind's Eye: A Multi-Faceted Reward Framework for Guiding Visual Metaphor Generation","type":"publication"},{"authors":["Dipankar Srirag","Aditya Joshi","Jordan Painter","Diptesh Kanojia"],"categories":null,"content":"","date":1753574400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1753574400,"objectID":"161136754e99d62896ac30673bbb3f42","permalink":"https://dipteshkanojia.co.uk/publication/srirag-etal-2025-besstie/","publishdate":"2025-07-27T00:00:00Z","relpermalink":"/publication/srirag-etal-2025-besstie/","section":"publication","summary":"Despite large language models (LLMs) being known to exhibit bias against non-mainstream varieties, there are no known labeled datasets for sentiment analysis of English. To address this gap, we introduce BESSTIE, a benchmark for sentiment and sarcasm classification for three varieties of English: Australian (en-AU), Indian (en-IN), and British (en-UK). Using web-based content from two domains, namely, Google Place reviews and Reddit comments, we collect datasets for these language varieties using two methods: location-based and topic-based filtering. Native speakers of the language varieties manually annotate the datasets with sentiment and sarcasm labels. To assess whether the dataset accurately represents these varieties, we conduct two validation steps: (a) manual annotation of language varieties and (b) automatic language variety prediction. We perform an additional annotation exercise to validate the reliance of the annotated labels. Subsequently, we fine-tune nine large language models (LLMs) (representing a range of encoder/decoder and mono/multilingual models) on these datasets, and evaluate their performance on the two tasks. Our results reveal that the models consistently perform better on inner-circle varieties (i.e., en-AU and en-UK), with significant performance drops for en-IN, particularly in sarcasm detection. We also report challenges in cross-variety generalisation, highlighting the need for language variety-specific datasets such as ours. BESSTIE promises to be a useful evaluative benchmark for future research in equitable LLMs, specifically in terms of language varieties. The BESSTIE dataset is publicly available at: https://huggingface.co/datasets/unswnlporg/BESSTIE.","tags":["sentiment analysis","sarcasm detection","varieties of English","benchmark","LLMs"],"title":"BESSTIE: A Benchmark for Sentiment and Sarcasm Classification for Varieties of English","type":"publication"},{"authors":["Shenbin Qian","Diptesh Kanojia","Samarth Agrawal","Hadeel Saadany","Swapnil Bhosale","Constantin Orăsan","Zhe Wu"],"categories":null,"content":"","date":1750809600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1750809600,"objectID":"8b61e4013cbecdf336a680ea25b8d35e","permalink":"https://dipteshkanojia.co.uk/publication/qian-etal-2025-near/","publishdate":"2025-06-25T00:00:00Z","relpermalink":"/publication/qian-etal-2025-near/","section":"publication","summary":"E-commerce information retrieval (IR) systems struggle to simultaneously achieve high accuracy in interpreting complex user queries and maintain efficient processing of vast product catalogs. The dual challenge lies in precisely matching user intent with relevant products while managing the computational demands of real-time search across massive inventories. In this paper, we propose a Nested Embedding Approach to product Retrieval and Ranking, called NEAR², which can achieve up to 12 times efficiency in embedding size at inference time while introducing no extra cost in training and improving performance in accuracy for various encoder-based Transformer models. We validate our approach using different loss functions for the retrieval and ranking task, including multiple negative ranking loss and online contrastive loss, on four different test sets with various IR challenges such as short and implicit queries. Our approach achieves an improved performance over a smaller embedding dimension, compared to any existing models.","tags":["product retrieval","ranking","e-commerce","embeddings","information retrieval"],"title":"NEAR²: A Nested Embedding Approach to Efficient Product Retrieval and Ranking","type":"publication"},{"authors":["Archchana Sindhujan","Diptesh Kanojia","Constantin Orăsan"],"categories":null,"content":"","date":1748736000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1748736000,"objectID":"815097b1ef1e0a5858d83401a41d6980","permalink":"https://dipteshkanojia.co.uk/publication/sindhujan-etal-2025-prompt/","publishdate":"2025-06-01T00:00:00Z","relpermalink":"/publication/sindhujan-etal-2025-prompt/","section":"publication","summary":"The aim of this project was to curate data for the English-Malayalam language pair for the tasks of Quality Estimation (QE) and Automatic Post-Editing (APE) of Machine Translation. Whilst the primary aim of the project was to create a dataset for a low-resource language pair, we plan to use this dataset to investigate different zero-shot and few-shot prompting strategies including chain-of-thought, towards a unified explainable QE-APE framework.","tags":["quality estimation","machine translation","English-Malayalam","explainable AI","low-resource languages"],"title":"Prompt-based Explainable Quality Estimation for English-Malayalam","type":"publication"},{"authors":["Diptesh Kanojia"],"categories":null,"content":"","date":1748732400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1748732400,"objectID":"666ac2f3987ed6a49a7066a063687640","permalink":"https://dipteshkanojia.co.uk/talk/ebay2025-search-safety/","publishdate":"2025-06-01T00:00:00+01:00","relpermalink":"/talk/ebay2025-search-safety/","section":"talk","summary":"Invited talk at eBay discussing the evolution from search relevance to content safety in information retrieval and GenAI-based systems.","tags":["talks","invited-talk","search-relevance","content-safety","information-retrieval"],"title":"From Search Relevance to Content Safety","type":"talk"},{"authors":["Girish A Koushik","Diptesh Kanojia","Helen Treharne"],"categories":null,"content":"","date":1747958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1747958400,"objectID":"2c928f94c6b3f2421db0fc611320e54a","permalink":"https://dipteshkanojia.co.uk/publication/koushik-etal-2025-multimodal-hate-detection/","publishdate":"2025-05-23T00:00:00Z","relpermalink":"/publication/koushik-etal-2025-multimodal-hate-detection/","section":"publication","summary":"Social media platforms enable the propagation of hateful content across different modalities such as textual, auditory, and visual, necessitating effective detection methods. While recent approaches have shown promise in handling individual modalities, their effectiveness across different modality combinations remains unexplored. Our paper presents a systematic analysis of fusion-based approaches for multimodal hate detection, focusing on performance across video and image-based content. Our comprehensive evaluation reveals significant modality-specific limitations: while simple embedding fusion achieves state-of-the-art performance on video content with a 9.9% points F1-score improvement, it struggles with complex image-text relationships in memes. Through detailed ablation studies and error analysis, we demonstrate how current fusion approaches fail to capture nuanced cross-modal interactions, particularly in cases involving benign confounders. Our findings provide crucial insights for developing more robust hate detection systems and highlight the need for modality-specific architectural considerations. The code is available at: https://github.com/surrey-nlp/Video-vs-Meme-Hate. **Note:** Awarded the Best Paper at the MM4SG workshop @ WWW 2025.","tags":["multimodal","hate-detection","video","image","social-media","fusion-methods"],"title":"Towards a Robust Framework for Multimodal Hate Detection: A Study on Video vs. Image-based Content","type":"publication"},{"authors":["Shenbin Qian","Constantin Orăsan","Diptesh Kanojia","Félix Do Carmo"],"categories":null,"content":"","date":1746057600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1746057600,"objectID":"291066500a7eadcb51795b680308f2f9","permalink":"https://dipteshkanojia.co.uk/publication/qian-etal-2025-automatically/","publishdate":"2025-05-01T00:00:00Z","relpermalink":"/publication/qian-etal-2025-automatically/","section":"publication","summary":"Evaluating machine translation (MT) of user-generated content (UGC) involves unique challenges such as checking whether the nuance of emotions from the source are preserved in the target text. Recent studies have proposed emotion-related datasets, frameworks and models to automatically evaluate MT quality of Chinese UGC, without relying on reference translations. However, whether these models are robust to the challenge of preserving emotional nuances has been left largely unexplored. To this end, we introduce a novel method inspired by information theory which generates challenging Chinese homophone words related to emotions, by leveraging the concept of *self-information*. Our approach generates homophones that were observed to cause translation errors in emotion preservation, and exposes vulnerabilities in MT models struggling to preserve relevant emotions. We evaluate the efficacy of our method using human evaluation and compare it with an existing one, showing that our method achieves higher correlation with human judgments. The generated Chinese homophones, along with their manual translations, are utilized to generate perturbations and to probe the robustness of existing quality evaluation models, including models trained using multi-task learning, fine-tuned variants of multilingual language models, as well as large language models (LLMs). Our results indicate that LLMs with larger size exhibit higher stability and robustness to such perturbations. We release our data and code for reproducibility and further research.","tags":["machine translation","homophones","quality estimation","Chinese","emotions"],"title":"Automatically Generating Chinese Homophone Words to Probe Machine Translation Estimation Systems","type":"publication"},{"authors":["Sourabh Deoghare","Diptesh Kanojia","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1745712000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1745712000,"objectID":"479b96de19d0f3917ea85dbb707857a4","permalink":"https://dipteshkanojia.co.uk/publication/deoghare-etal-2025-giving/","publishdate":"2025-04-27T00:00:00Z","relpermalink":"/publication/deoghare-etal-2025-giving/","section":"publication","summary":"Automatic Post-Editing (APE) systems often struggle with over-correction, where unnecessary modifications are made to a translation, diverging from the principle of minimal editing. In this paper, we propose a novel technique to mitigate over-correction by incorporating word-level Quality Estimation (QE) information during the decoding process. This method is architecture-agnostic, making it adaptable to any APE system, regardless of the underlying model or training approach. Our experiments on English-German, English-Hindi, and English-Marathi language pairs show the proposed approach yields significant improvements over their corresponding baseline APE systems, with TER gains of 0.65, 1.86, and 1.44 points, respectively. These results underscore the complementary relationship between QE and APE tasks and highlight the effectiveness of integrating QE information to reduce over-correction in APE systems.","tags":["automatic post-editing","quality estimation","constrained decoding","machine translation"],"title":"Giving the Old a Fresh Spin: Quality Estimation-Assisted Constrained Decoding for Automatic Post-Editing","type":"publication"},{"authors":["Girish A Koushik","Diptesh Kanojia","Helen Treharne","Aditya Joshi"],"categories":null,"content":"","date":1745539200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1745539200,"objectID":"1146de2b1d1aef681138a7c4f632f7d7","permalink":"https://dipteshkanojia.co.uk/publication/koushik-etal-2025-camu/","publishdate":"2025-04-25T00:00:00Z","relpermalink":"/publication/koushik-etal-2025-camu/","section":"publication","summary":"","tags":["meme understanding","context augmentation","multimodal"],"title":"CAMU: Context Augmentation for Meme Understanding","type":"publication"},{"authors":["Swapnil Bhosale","Haosen Yang","Diptesh Kanojia","Jiankang Deng","Xiatian Zhu"],"categories":null,"content":"","date":1744329600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1744329600,"objectID":"a0300bfd272dc9a024929ed6cac750e2","permalink":"https://dipteshkanojia.co.uk/publication/bhosale-etal-2025-unsupervised/","publishdate":"2025-04-11T00:00:00Z","relpermalink":"/publication/bhosale-etal-2025-unsupervised/","section":"publication","summary":"Audio-Visual Segmentation (AVS) aims to identify, at the pixel level, the object in a visual scene that produces a given sound. Current AVS methods rely on costly fine-grained annotations of mask-audio pairs, making them impractical for scalability. To address this, we propose the Modality Correspondence Alignment (MoCA) framework, which seamlessly integrates off-the-shelf foundation models like DINO, SAM, and ImageBind. Our approach leverages existing knowledge within these models and optimizes their joint usage for multimodal associations. Our approach relies on estimating positive and negative image pairs in the feature space. For pixel-level association, we introduce an audio-visual adapter and a novel pixel matching aggregation strategy within the image-level contrastive learning framework. This allows for a flexible connection between object appearance and audio signal at the pixel level, with tolerance to imaging variations such as translation and rotation. Extensive experiments on the AVSBench (single and multi-object splits) and AVSS datasets demonstrate that MoCA outperforms unsupervised baseline approaches and some supervised counterparts, particularly in complex scenarios with multiple auditory objects. In terms of mIoU, MoCA achieves a substantial improvement over baselines in both the AVSBench (S4: +17.24%, MS3: +67.64%) and AVSS (+19.23%) audio-visual segmentation challenges.","tags":["audio-visual segmentation","unsupervised learning","foundation models","modality alignment"],"title":"Unsupervised Audio-Visual Segmentation with Modality Alignment","type":"publication"},{"authors":["Xinran Liu","Zhenhua Feng","Diptesh Kanojia","Wenwu Wang"],"categories":null,"content":"","date":1740700800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1740700800,"objectID":"917ac5fe462c9fbb09b2c13702531e98","permalink":"https://dipteshkanojia.co.uk/publication/liu-etal-2025-dgfm/","publishdate":"2025-02-28T00:00:00Z","relpermalink":"/publication/liu-etal-2025-dgfm/","section":"publication","summary":"In music-driven dance motion generation, most existing methods use hand-crafted features and neglect that music foundation models have profoundly impacted cross-modal content generation. To bridge this gap, we propose a diffusion-based method that generates dance movements conditioned on text and music. Our approach extracts music features by combining high-level features obtained by music foundation model with hand-crafted features, thereby enhancing the quality of generated dance sequences. This method effectively leverages the advantages of high-level semantic information and low-level temporal details to improve the model's capability in music feature understanding. To show the merits of the proposed method, we compare it with four music foundation models and two sets of hand-crafted music features. The results demonstrate that our method obtains the most realistic dance sequences and achieves the best match with the input music.","tags":["dance generation","music foundation models","diffusion","cross-modal"],"title":"DGFM: Full Body Dance Generation Driven by Music Foundation Models","type":"publication"},{"authors":["Xinran Liu","Xu Dong","Diptesh Kanojia","Wenwu Wang","Zhenhua Feng"],"categories":null,"content":"","date":1740700800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1740700800,"objectID":"ecdcda99029eede0a4d3a344a6b6a246","permalink":"https://dipteshkanojia.co.uk/publication/liu-etal-2025-gcdance/","publishdate":"2025-02-28T00:00:00Z","relpermalink":"/publication/liu-etal-2025-gcdance/","section":"publication","summary":"","tags":["dance generation","music-driven","3D","genre-controlled"],"title":"GCDance: Genre-Controlled 3D Full Body Dance Generation Driven By Music","type":"publication"},{"authors":["Aditya Joshi","Raj Dabre","Diptesh Kanojia","Zhuang Li","Haolan Zhan","Gholamreza Haffari","Doris Dippold"],"categories":null,"content":"","date":1739145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1739145600,"objectID":"145945ca9bcea0a0a1f2068e4956a57f","permalink":"https://dipteshkanojia.co.uk/publication/joshi-etal-2025-natural/","publishdate":"2025-02-10T00:00:00Z","relpermalink":"/publication/joshi-etal-2025-natural/","section":"publication","summary":"State-of-the-art natural language processing (NLP) models are trained on massive training corpora, and report a superlative performance on evaluation datasets. This survey delves into an important attribute of these datasets: the dialect of a language. Motivated by the performance degradation of NLP models for dialectal datasets and its implications for the equity of language technologies, we survey past research in NLP for dialects in terms of datasets, and approaches. We describe a wide range of NLP tasks in terms of two categories: natural language understanding (NLU) (for tasks such as dialect classification, sentiment analysis, parsing, and NLU benchmarks) and natural language generation (NLG) (for summarisation, machine translation, and dialogue systems). The survey is also broad in its coverage of languages which include English, Arabic, German, among others. We observe that past work in NLP concerning dialects goes deeper than mere dialect classification, and extends to several NLU and NLG tasks. For these tasks, we describe classical machine learning using statistical models, along with the recent deep learning-based approaches based on pre-trained language models. We expect that this survey will be useful to NLP researchers interested in building equitable language technologies by rethinking LLM benchmarks and model architectures.","tags":["natural language processing","dialects","survey","equity in language technologies"],"title":"Natural Language Processing for Dialects of a Language: A Survey","type":"publication"},{"authors":["Sourabh Dattatray Deoghare","Diptesh Kanojia","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1735689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735689600,"objectID":"5218d9db53d45fbfdfa97dc576f6fe54","permalink":"https://dipteshkanojia.co.uk/publication/deoghare-etal-2025-refer/","publishdate":"2025-01-01T00:00:00Z","relpermalink":"/publication/deoghare-etal-2025-refer/","section":"publication","summary":"","tags":["automatic post-editing","data generation","machine translation"],"title":"Refer to the Reference: Reference-focused Synthetic Automatic Post-Editing Data Generation","type":"publication"},{"authors":["Archchana Sindhujan","Diptesh Kanojia","Constantin Orăsan","Shenbin Qian"],"categories":null,"content":"","date":1735689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735689600,"objectID":"c1d8abd17f43844f26c1bde1996aa199","permalink":"https://dipteshkanojia.co.uk/publication/sindhujan-etal-2025-llms/","publishdate":"2025-01-01T00:00:00Z","relpermalink":"/publication/sindhujan-etal-2025-llms/","section":"publication","summary":"This paper investigates the reference-less evaluation of machine translation for low-resource language pairs, known as quality estimation (QE). Segment-level QE is a challenging cross-lingual language understanding task that provides a quality score (0 -100) to the translated output. We comprehensively evaluate large language models (LLMs) in zero/few-shot scenarios and perform instruction fine-tuning using a novel prompt based on annotation guidelines. Our results indicate that prompt-based approaches are outperformed by the encoder-based fine-tuned QE models. Our error analysis reveals tokenization issues, along with errors due to transliteration and named entities, and argues for refinement in LLM pre-training for cross-lingual tasks. We release the data, and models trained publicly for further research.","tags":["quality estimation","machine translation","low-resource languages","LLMs"],"title":"When LLMs Struggle: Reference-less Translation Evaluation for Low-resource Languages","type":"publication"},{"authors":["Fatemeh Nazarieh","Zhenhua Feng","Diptesh Kanojia","Muhammad Awais","Josef Kittler"],"categories":null,"content":"","date":1733875200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733875200,"objectID":"fa92112e926d0da96690a028d0e7bbb6","permalink":"https://dipteshkanojia.co.uk/publication/nazarieh-etal-2024-portraittalk/","publishdate":"2024-12-11T00:00:00Z","relpermalink":"/publication/nazarieh-etal-2024-portraittalk/","section":"publication","summary":"Audio-driven talking face generation is a challenging task in digital communication. Despite significant progress in the area, most existing methods concentrate on audio-lip synchronization, often overlooking aspects such as visual quality, customization, and generalization that are crucial to producing realistic talking faces. To address these limitations, we introduce a novel, customizable one-shot audio-driven talking face generation framework, named PortraitTalk. Our proposed method utilizes a latent diffusion framework consisting of two main components: IdentityNet and AnimateNet. IdentityNet is designed to preserve identity features consistently across the generated video frames, while AnimateNet aims to enhance temporal coherence and motion consistency. This framework also integrates an audio input with the reference images, thereby reducing the reliance on reference-style videos prevalent in existing approaches. A key innovation of PortraitTalk is the incorporation of text prompts through decoupled cross-attention mechanisms, which significantly expands creative control over the generated videos. Through extensive experiments, including a newly developed evaluation metric, our model demonstrates superior performance over the state-of-the-art methods, setting a new standard for the generation of customizable realistic talking faces suitable for real-world applications.","tags":["audio-to-talking face generation","diffusion models","customization","one-shot"],"title":"PortraitTalk: Towards Customizable One-Shot Audio-to-Talking Face Generation","type":"publication"},{"authors":["Swapnil Bhosale","Haosen Yang","Diptesh Kanojia","Jiankang Deng","Xiatian Zhu"],"categories":null,"content":"","date":1733788800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733788800,"objectID":"3cb6aa0e8336738e563ecaebb888a0b9","permalink":"https://dipteshkanojia.co.uk/publication/bhosale-etal-2024-av/","publishdate":"2024-12-10T00:00:00Z","relpermalink":"/publication/bhosale-etal-2024-av/","section":"publication","summary":"Novel view acoustic synthesis (NVAS) aims to render binaural audio at any target viewpoint, given a mono audio emitted by a sound source at a 3D scene. Existing methods have proposed NeRF-based implicit models to exploit visual cues as a condition for synthesizing binaural audio. However, in addition to low efficiency originating from heavy NeRF rendering, these methods all have a limited ability of characterizing the entire scene environment such as room geometry, material properties, and the spatial relation between the listener and sound source. To address these issues, we propose a novel Audio-Visual Gaussian Splatting (AV-GS) model. To obtain a material-aware and geometry-aware condition for audio synthesis, we learn an explicit point-based scene representation with an audio-guidance parameter on locally initialized Gaussian points, taking into account the space relation from the listener and sound source. To make the visual scene model audio adaptive, we propose a point densification and pruning strategy to optimally distribute the Gaussian points, with the per-point contribution in sound propagation (e.g., more points needed for texture-less wall surfaces as they affect sound path diversion). Extensive experiments validate the superiority of our AV-GS over existing alternatives on the real-world RWAS and simulation-based SoundSpaces datasets.","tags":["acoustic synthesis","gaussian splatting","novel view synthesis","audio-visual"],"title":"AV-GS: Learning Material and Geometry aware Priors for Novel View Acoustic Synthesis","type":"publication"},{"authors":["Fatemeh Nazarieh","Josef Kittler","Muhammad Awais Rana","Diptesh Kanojia","Zhenhua Feng"],"categories":null,"content":"","date":1733184000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733184000,"objectID":"4bb8705fca306f0e157f8561134ecd04","permalink":"https://dipteshkanojia.co.uk/publication/nazarieh-etal-2025-stabletalk/","publishdate":"2024-12-03T00:00:00Z","relpermalink":"/publication/nazarieh-etal-2025-stabletalk/","section":"publication","summary":"Audio-to-talking face generation stands at the forefront of advancements in generative AI. It bridges the gap between audio and visual representations by generating synchronized and realistic talking faces. Despite recent progress, the lack of realism in animated faces, asynchronous audio-lip movements, and computational burden remain key barriers to practical applications. To address these challenges, we introduce a novel approach, StableTalk, leveraging the emerging capabilities of Stable diffusion models and vision Transformers for Talking face generation. We also integrate the Re-attention mechanism and adversarial loss to improve the consistency of facial animations and synchronization with a given audio input. More importantly, the computational efficiency of our method has been notably enhanced by optimizing operations within the latent space and dynamically adjusting the focus on different parts of the visual content based on the provided conditions. Our experimental results demonstrate the superiority of StableTalk over the existing approaches in image quality, audio-lip synchronization, and computational efficiency.","tags":["audio-to-talking face generation","stable diffusion","vision transformer","generative AI"],"title":"StableTalk: Advancing Audio-to-Talking Face Generation with Stable Diffusion and Vision Transformer","type":"publication"},{"authors":["Shenbin Qian","Constantin Orăsan","Diptesh Kanojia","Félix Do Carmo"],"categories":null,"content":"","date":1731974400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1731974400,"objectID":"ca0937d85a12a7eba08e801793bd17cf","permalink":"https://dipteshkanojia.co.uk/publication/qian-etal-2024-multi/","publishdate":"2024-11-19T00:00:00Z","relpermalink":"/publication/qian-etal-2024-multi/","section":"publication","summary":"Machine translation (MT) of user-generated content (UGC) poses unique challenges, including handling slang, emotion, and literary devices like irony and sarcasm. Evaluating the quality of these translations is challenging as current metrics do not focus on these ubiquitous features of UGC. To address this issue, we utilize an existing emotion-related dataset that includes emotion labels and human-annotated translation errors based on Multi-dimensional Quality Metrics. We extend it with sentence-level evaluation scores and word-level labels, leading to a dataset suitable for sentence- and word-level translation evaluation and emotion classification, in a multi-task setting. We propose a new architecture to perform these tasks concurrently, with a novel combined loss function, which integrates different loss heuristics, like the Nash and Aligned losses. Our evaluation compares existing fine-tuning and multi-task learning approaches, assessing generalization with ablative experiments over multiple datasets. Our approach achieves state-of-the-art performance and we present a comprehensive analysis for MT evaluation of UGC.","tags":["machine translation","emotion","user-generated content","multi-task learning"],"title":"A Multi-task Learning Framework for Evaluating Machine Translation of Emotion-loaded User-generated Content","type":"publication"},{"authors":["Shenbin Qian","Constantin Orăsan","Diptesh Kanojia","Félix Do Carmo"],"categories":null,"content":"","date":1731974400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1731974400,"objectID":"253dfb3bfc3a41f274a521f21f5b2dfd","permalink":"https://dipteshkanojia.co.uk/publication/qian-etal-2024-large-language/","publishdate":"2024-11-19T00:00:00Z","relpermalink":"/publication/qian-etal-2024-large-language/","section":"publication","summary":"This paper investigates whether large language models (LLMs) are state-of-the-art quality estimators for machine translation of user-generated content (UGC) that contains emotional expressions, without the use of reference translations. To achieve this, we employ an existing emotion-related dataset with human-annotated errors and calculate quality evaluation scores based on the Multi-dimensional Quality Metrics. We compare the accuracy of several LLMs with that of our fine-tuned baseline models, under in-context learning and parameter-efficient fine-tuning (PEFT) scenarios. We find that PEFT of LLMs leads to better performance in score prediction with human interpretable explanations than fine-tuned models. However, a manual analysis of LLM outputs reveals that they still have problems such as refusal to reply to a prompt and unstable output while evaluating machine translation of UGC.","tags":["large language models","machine translation","quality estimation","user-generated content"],"title":"Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?","type":"publication"},{"authors":["Chrysoula Zerva","Frederic Blain","José G. C. De Souza","Diptesh Kanojia","Sourabh Deoghare","Nuno M. Guerreiro","Giuseppe Attanasio","Ricardo Rei","Constantin Orăsan","Matteo Negri","Marco Turchi","Rajen Chatterjee","Pushpak Bhattacharyya","Markus Freitag","André Martins"],"categories":null,"content":"","date":1731974400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1731974400,"objectID":"bfb5945e883755174a6f6d5e09319482","permalink":"https://dipteshkanojia.co.uk/publication/zerva-etal-2024-findings/","publishdate":"2024-11-19T00:00:00Z","relpermalink":"/publication/zerva-etal-2024-findings/","section":"publication","summary":"We report the results of the WMT 2024 shared task on Quality Estimation, in which the challenge is to predict the quality of the output of neural machine translation systems at the word and sentence levels, without access to reference translations. In this edition, we expanded our scope to assess the potential for quality estimates to help in the correction of translated outputs, hence including an automated post-editing (APE) direction. We publish new test sets with human annotations that target two directions: providing new Multidimensional Quality Metrics (MQM) annotations for three multi-domain language pairs (English to German, Spanish and Hindi) and extending the annotations on Indic languages providing direct assessments and post edits for translation from English into Hindi, Gujarati, Tamil and Telugu. We also perform a detailed analysis of the behaviour of different models with respect to different phenomena including gender bias, idiomatic language, and numerical and entity perturbations. We received submissions based both on traditional, encoder-based approaches as well as large language model (LLM) based ones.","tags":["quality estimation","machine translation","shared task","LLMs"],"title":"Findings of the Quality Estimation Shared Task at WMT 2024: Are LLMs Closing the Gap in QE?","type":"publication"},{"authors":["Hadeel Saadany","Swapnil Bhosale","Samarth Agrawal","Diptesh Kanojia","Constantin Orăsan","Zhe Wu"],"categories":null,"content":"","date":1731369600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1731369600,"objectID":"be46fd35c0c2e5386dff88294c9e007b","permalink":"https://dipteshkanojia.co.uk/publication/saadany-etal-2024-centrality/","publishdate":"2024-11-12T00:00:00Z","relpermalink":"/publication/saadany-etal-2024-centrality/","section":"publication","summary":"This paper addresses the challenge of improving user experience on e-commerce platforms by enhancing product ranking relevant to user's search queries. Ambiguity and complexity of user queries often lead to a mismatch between user's intent and retrieved product titles or documents. Recent approaches have proposed the use of Transformer-based models which need millions of annotated query-title pairs during the pre-training stage, and this data often does not take user intent into account. To tackle this, we curate samples from existing datasets at eBay, manually annotated with buyer-centric relevance scores, and centrality scores which reflect how well the product title matches the user's intent. We introduce a User-intent Centrality Optimization (UCO) approach for existing models, which optimizes for the user intent in semantic product search. To that end, we propose a dual-loss based optimization to handle hard negatives, i.e., product titles that are semantically relevant but do not reflect the user's intent. Our contributions include curating challenging evaluation sets and implementing UCO, resulting in significant improvements in product ranking efficiency, observed for different evaluation metrics. Our work aims to ensure that the most buyer-centric titles for a query are ranked higher, thereby, enhancing the user experience on e-commerce platforms.","tags":["product retrieval","ranking","e-commerce","user intent"],"title":"Centrality-aware Product Retrieval and Ranking","type":"publication"},{"authors":["Sourabh Deoghare","Diptesh Kanojia","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1731369600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1731369600,"objectID":"debaf5acef86d84ba8790ec5804d66c3","permalink":"https://dipteshkanojia.co.uk/publication/deoghare-etal-2024-together/","publishdate":"2024-11-12T00:00:00Z","relpermalink":"/publication/deoghare-etal-2024-together/","section":"publication","summary":"This exploratory study investigates the potential of multilingual Automatic Post-Editing (APE) systems to enhance the quality of machine translations for low-resource Indo-Aryan languages. Focusing on two closely related language pairs, English-Marathi and English-Hindi, we exploit the linguistic similarities to develop a robust multilingual APE model. To facilitate cross-linguistic transfer, we generate synthetic Hindi-Marathi and Marathi-Hindi APE triplets. Additionally, we incorporate a Quality Estimation (QE)-APE multi-task learning framework. While the experimental results underline the complementary nature of APE and QE, we also observe that QE-APE multitask learning facilitates effective domain adaptation. Our experiments demonstrate that the multilingual APE models outperform their corresponding English-Hindi and English-Marathi single-pair models by 2.5 and 2.39 TER points, respectively, with further notable improvements over the multilingual APE model observed through multi-task learning (+1.29 and +1.44 TER points), data augmentation (+0.53 and +0.45 TER points) and domain adaptation (+0.35 and +0.45 TER points). We release the synthetic data, code, and models accrued during this study publicly for further research.","tags":["automatic post-editing","multilingual","low-resource languages","machine translation"],"title":"Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages","type":"publication"},{"authors":["Shenbin Qian","Archchana Sindhujan","Minnie Kabra","Diptesh Kanojia","Constantin Orăsan","Tharindu Ranasinghe","Fred Blain"],"categories":null,"content":"","date":1731369600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1731369600,"objectID":"a5325a87a3bec81a35d29cf27177e545","permalink":"https://dipteshkanojia.co.uk/publication/qian-etal-2024-large/","publishdate":"2024-11-12T00:00:00Z","relpermalink":"/publication/qian-etal-2024-large/","section":"publication","summary":"Leveraging large language models (LLMs) for various natural language processing tasks has led to superlative claims about their performance. For the evaluation of machine translation (MT), existing research shows that LLMs are able to achieve results comparable to fine-tuned multilingual pre-trained language models. In this paper, we explore what translation information, such as the source, reference, translation errors and annotation guidelines, is needed for LLMs to evaluate MT quality. In addition, we investigate prompting techniques such as zero-shot, Chain of Thought (CoT) and few-shot prompting for eight language pairs covering high-, medium- and low-resource languages, leveraging varying LLM variants. Our findings indicate the importance of reference translations for an LLM-based evaluation. While larger models do not necessarily fare better, they tend to benefit more from CoT prompting, than smaller models. We also observe that LLMs do not always provide a numerical score when generating evaluations, which poses a question on their reliability for the task. Our work presents a comprehensive analysis for resource-constrained and training-less LLM-based evaluation of machine translation. We release the accrued prompt templates, code and data publicly for reproducibility.","tags":["machine translation","large language models","evaluation","prompting"],"title":"What do Large Language Models Need for Machine Translation Evaluation?","type":"publication"},{"authors":["Hadeel Saadany","Swapnil Bhosale","Samarth Agrawal","Zhe Wu","Constantin Orăsan","Diptesh Kanojia"],"categories":null,"content":"","date":1729468800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729468800,"objectID":"490f7fe0ede70ac990e0d5003663e263","permalink":"https://dipteshkanojia.co.uk/publication/saadany-etal-2024-product/","publishdate":"2024-10-21T00:00:00Z","relpermalink":"/publication/saadany-etal-2024-product/","section":"publication","summary":"This talk addresses the challenge of improving user experience on e-commerce platforms by enhancing product ranking relevant to user's search queries. Queries such as S2716DG consist of alphanumeric characters where a letter or number can signify important detail for the product/model. Speaker describes recent research where we curate samples from existing datasets at eBay, manually annotated with buyer-centric relevance scores, and centrality scores which reflect how well the product title matches the user's intent. We introduce a User-intent Centrality Optimization (UCO) approach for existing models, which optimizes for the user intent in semantic product search. To that end, we propose a dual-loss based optimization to handle hard negatives, i.e., product titles that are semantically relevant but do not reflect the user's intent. Our contributions include curating a challenging evaluation set and implementing UCO, resulting in significant improvements in product ranking efficiency, observed for different evaluation metrics. Our work aims to ensure that the most buyer-centric titles for a query are ranked higher, thereby, enhancing the user experience on e-commerce platforms.","tags":["product retrieval","ranking","alphanumeric queries","e-commerce"],"title":"Product Retrieval and Ranking for Alphanumeric Queries","type":"publication"},{"authors":["Dipankar Srirag","Jordan Painter","Aditya Joshi","Diptesh Kanojia"],"categories":null,"content":"","date":1729036800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729036800,"objectID":"5f73c6c14eeb7a0df443493128afeac4","permalink":"https://dipteshkanojia.co.uk/publication/srirag-etal-2024-experiences/","publishdate":"2024-10-16T00:00:00Z","relpermalink":"/publication/srirag-etal-2024-experiences/","section":"publication","summary":"Existing benchmarks often fail to account for linguistic diversity, like language variants of English. In this paper, we share our experiences from our ongoing project of building a sentiment classification benchmark for three variants of English: Australian (en-AU), Indian (en-IN), and British (en-UK) English. Using Google Places reviews, we explore the effects of various sampling techniques based on label semantics, review length, and sentiment proportion and report performances on three fine-tuned BERT-based models. Our initial evaluation reveals significant performance variations influenced by sample characteristics, label semantics, and language variety, highlighting the need for nuanced benchmark design. We offer actionable insights for researchers to create robust benchmarks, emphasising the importance of diverse sampling, careful label definition, and comprehensive evaluation across linguistic varieties.","tags":["sentiment classification","benchmarks","varieties of English","sampling"],"title":"Experiences from Creating a Benchmark for Sentiment Classification for Varieties of English","type":"publication"},{"authors":["Dipankar Srirag","Jordan Painter","Aditya Joshi","Diptesh Kanojia"],"categories":null,"content":"","date":1729036800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729036800,"objectID":"824a3196127a326b5e9e8e3326eb3de8","permalink":"https://dipteshkanojia.co.uk/publication/srirag-etal-2024-sampling/","publishdate":"2024-10-16T00:00:00Z","relpermalink":"/publication/srirag-etal-2024-sampling/","section":"publication","summary":"This paper investigates data sampling strategies to create a benchmark for dialectal sentiment classification of Google Places reviews written in English. Based on location-based filtering, we collect a self-supervised dataset of reviews in Australian (Australian English), Indian (Indian English), and British (British English) English with self-supervised sentiment labels (1-star to 5-star). We employ sampling techniques based on label semantics, review length, and sentiment proportion and report performances on three fine-tuned BERT-based models. Our multi-dialect evaluation provides pointers to challenging scenarios for inner-circle (Australian English and British English) as well as non-native dialects (Indian English) of English, highlighting the need for more diverse benchmarks.","tags":["sentiment classification","dialects","benchmark","sampling strategies"],"title":"Sampling Strategies for Creation of a Benchmark for Dialectal Sentiment Classification","type":"publication"},{"authors":["Félix do Carmo","Diptesh Kanojia"],"categories":null,"content":"","date":1728345600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728345600,"objectID":"f1fb133f0f332271a1a802d08fd241dc","permalink":"https://dipteshkanojia.co.uk/publication/carmo-etal-2024-edit/","publishdate":"2024-10-08T00:00:00Z","relpermalink":"/publication/carmo-etal-2024-edit/","section":"publication","summary":"The tutorial describes the concept of edit distances applied to research and commercial contexts. We use Translation Edit Rate (TER), Levenshtein, Damerau-Levenshtein, Longest Common Subsequence and n-gram distances to demonstrate the frailty of statistical metrics when comparing text sequences. Our discussion disassembles them into their essential components. We discuss the centrality of four editing actions: insert, delete, replace and move words, and show their implementations in openly available packages and toolkits. The application of edit distances in downstream tasks often assumes that these accurately represent work done by post-editors and real errors that need to be corrected in MT output. We discuss how imperfect edit distances are in capturing the details of this error correction work and the implications for researchers and for commercial applications, of these uses of edit distances. In terms of commercial applications, we discuss their integration in computer-assisted translation tools and how the perception of the connection between edit distances and post-editor effort affects the definition of translator rates.","tags":["edit distances","machine translation","tutorial","commercial applications"],"title":"Edit Distances and Their Applications to Downstream Tasks in Research and Commercial Contexts","type":"publication"},{"authors":["Aditya Joshi","Diptesh Kanojia","Heather Lent","Hour Kaing","Haiyue Song"],"categories":null,"content":"","date":1727136000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727136000,"objectID":"f95b648a887f3cccc2934d53e9832def","permalink":"https://dipteshkanojia.co.uk/publication/joshi-etal-2024-connecting/","publishdate":"2024-09-24T00:00:00Z","relpermalink":"/publication/joshi-etal-2024-connecting/","section":"publication","summary":"Despite excellent results on benchmarks over a small subset of languages, large language models struggle to process text from languages situated in 'lower-resource' scenarios such as dialects/sociolects (national or social varieties of a language), Creoles (languages arising from linguistic contact between multiple languages) and other low-resource languages. This introductory tutorial will identify common challenges, approaches, and themes in natural language processing (NLP) research for confronting and overcoming the obstacles inherent to data-poor contexts. By connecting past ideas to the present field, this tutorial aims to ignite collaboration and cross-pollination between researchers working in these scenarios. Our notion of 'lower-resource' broadly denotes the outstanding lack of data required for model training - and may be applied to scenarios apart from the three covered in the tutorial.","tags":["NLP","low-resource languages","dialects","creoles","tutorial"],"title":"Connecting Ideas in 'Lower-Resource' Scenarios: NLP for National Varieties, Creoles and Other Low-resource Scenarios","type":"publication"},{"authors":["Shafkat Farabi","Tharindu Ranasinghe","Diptesh Kanojia","Yu Kong","Marcos Zampieri"],"categories":null,"content":"","date":1722643200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1722643200,"objectID":"eaa46ae17bed1f3fd8c6b4a0bfc83d09","permalink":"https://dipteshkanojia.co.uk/publication/farabi-etal-2024-survey/","publishdate":"2024-08-03T00:00:00Z","relpermalink":"/publication/farabi-etal-2024-survey/","section":"publication","summary":"Sarcasm is a rhetorical device that is used to convey the opposite of the literal meaning of an utterance. Sarcasm is widely used on social media and other forms of computer-mediated communication motivating the use of computational models to identify it automatically. While the clear majority of approaches to sarcasm detection have been carried out on text only, sarcasm detection often requires additional information present in tonality, facial expression, and contextual images. This has led to the introduction of multimodal models, opening the possibility to detect sarcasm in multiple modalities such as audio, images, text, and video. In this paper, we present the first comprehensive survey on multimodal sarcasm detection - henceforth MSD - to date. We survey papers published between 2018 and 2023 on the topic, and discuss the models and datasets used for this task. We also present future research directions in MSD.","tags":["sarcasm detection","multimodal","survey"],"title":"A Survey of Multimodal Sarcasm Detection","type":"publication"},{"authors":["Archchana Sindhujan","Diptesh Kanojia","Constantin Orăsan"],"categories":null,"content":"","date":1719964800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719964800,"objectID":"204e43f87489a17f4d28aa08b9a15624","permalink":"https://dipteshkanojia.co.uk/publication/sindhujan-etal-2024-optimizing/","publishdate":"2024-07-03T00:00:00Z","relpermalink":"/publication/sindhujan-etal-2024-optimizing/","section":"publication","summary":"Quality Estimation (QE) is vital to determine the effectiveness of MT systems. This paper investigates QE for machine translation (MT) for low-resource Indic languages. We analyse the influence of language relatedness within linguistic families and integrate various pre-trained encoders within the MonoTransQuest (MonoTQ) framework. This entails assessing models in single-language configurations before scaling up to multiple-language setups, focusing on languages within and across families, and using approaches grounded in transfer learning. Experimental outcomes and analyses indicate that language-relatedness significantly improves QE performance over baseline, sometimes even surpassing state-of-the-art approaches. Across monolingual and multilingual configurations, we discuss strategic encoder usage as a simple measure to exploit the language interactions within these models improving baseline QE efficiency for quality estimation. This investigation underscores the potential of tailored pre-trained encoders to improve QE performance and discusses the limitations of QE approaches for low-resource scenarios.","tags":["quality estimation","machine translation","low-resource languages","language relatedness"],"title":"Optimizing Quality Estimation for Low-Resource Language Translations: Exploring the Role of Language Relatedness","type":"publication"},{"authors":["Shenbin Qian","Constantin Orăsan","Félix Do Carmo","Diptesh Kanojia"],"categories":null,"content":"","date":1719360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719360000,"objectID":"616b5905d9af3e5d0df3b5de30803f3e","permalink":"https://dipteshkanojia.co.uk/publication/qian-etal-2024-evaluating/","publishdate":"2024-06-26T00:00:00Z","relpermalink":"/publication/qian-etal-2024-evaluating/","section":"publication","summary":"This paper presents a dataset for evaluating the machine translation of emotion-loaded user generated content. It contains human-annotated quality evaluation data and post-edited reference translations. The dataset is available at our GitHub repository.","tags":["machine translation","emotion","user generated content","evaluation"],"title":"Evaluating Machine Translation for Emotion-loaded User Generated Content (TransEval4Emo-UGC)","type":"publication"},{"authors":["Aisha Saeid","Diptesh Kanojia","Ferrante Neri"],"categories":null,"content":"","date":1719273600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719273600,"objectID":"c9d398787d4a5c559718d8405d014a1c","permalink":"https://dipteshkanojia.co.uk/publication/saeid-etal-2024-decoding/","publishdate":"2024-06-25T00:00:00Z","relpermalink":"/publication/saeid-etal-2024-decoding/","section":"publication","summary":"Social media, a vast platform for communication and entertainment, unfortunately, is an ideal breeding ground for cyberbullying. While most common among teenagers, it also affects other demographics. Despite strict zero-tolerance policies on social media, the elusive nature of cyberbullying persists. Simple word searches are insufficient, leading to the exploration of Natural Language Processing (NLP) to detect and classify cyberbullying. This study balances result accuracy with model simplicity, crucial for an effective detector. Quick identification of offensive content is essential to combat cyberbullying. The ever-changing slang and trends require an easily updatable detector. Using a cyberbullying dataset from real tweets on X (formerly Twitter), this study initially applies traditional machine learning algorithms, including Logistic Regression, Support Vector Machines, Decision Trees, and Random Forests. The investigation then moves to Transformers-based autoencoders from the BERT family, including sentence-transformers. However, these models require significant memory and disk space due to their large number of training parameters. The study focuses on the efficiency of cyberbullying detectors using character-level language models based on the bidirectional long-short-term memory (BiLSTM) neural architecture. Our experiments demonstrate that these detectors offer comparable performance and provide a practical option for real-world deployment.","tags":["cyberbullying","social media","machine learning"],"title":"Decoding Cyberbullying on Social Media: A Machine Learning Exploration","type":"publication"},{"authors":["Leonardo Zilio","Shenbin Qian","Diptesh Kanojia","Constantin Orăsan"],"categories":null,"content":"","date":1716163200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1716163200,"objectID":"a202d2a102d087b16815309d2df2e179","permalink":"https://dipteshkanojia.co.uk/publication/zilio-etal-2024-using/","publishdate":"2024-05-20T00:00:00Z","relpermalink":"/publication/zilio-etal-2024-using/","section":"publication","summary":"Abbreviations and their associated long forms are important textual elements that are present in almost every scientific communication, and having information about these forms can help improve several NLP tasks. In this paper, our aim is to fine-tune language models for automatically identifying abbreviations and long forms. We used existing datasets which are annotated with abbreviations and long forms to train and test several language models, including transformer models, character-level language models, stacking of different embeddings, and ensemble methods. Our experiments showed that it was possible to achieve state-of-the-art results by stacking RoBERTa embeddings with domain-specific embeddings. However, the analysis of our first run showed that one of the datasets had issues in the BIO annotation, which led us to propose a revised dataset. After re-training selected models on the revised dataset, results show that character-level models achieve comparable results, especially when detecting abbreviations, but both RoBERTa large and the stacking of embeddings presented better results on biomedical data. When tested on a different subdomain (segments extracted from computer science texts), an ensemble method proved to yield the best results for the detection of long forms, and a character-level model had the best performance in detecting abbreviations.","tags":["abbreviation detection","character-level models","NLP","biomedical text"],"title":"Using character-level models for efficient abbreviation and long-form detection","type":"publication"},{"authors":["Swapnil Bhosale","Sauradip Nag","Diptesh Kanojia","Jiankang Deng","Xiatian Zhu"],"categories":null,"content":"","date":1711238400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711238400,"objectID":"da9061142a5a5002a6f77c3af9e8c87b","permalink":"https://dipteshkanojia.co.uk/publication/bhosale-etal-2024-diffsed/","publishdate":"2024-03-24T00:00:00Z","relpermalink":"/publication/bhosale-etal-2024-diffsed/","section":"publication","summary":"Sound Event Detection (SED) aims to predict the temporal boundaries of all the events of interest and their class labels, given an unconstrained audio sample. Taking either the split-and-classify (i.e., frame-level) strategy or the more principled event-level modeling approach, all existing methods consider the SED problem from the discriminative learning perspective. In this work, we reformulate the SED problem by taking a generative learning perspective. Specifically, we aim to generate sound temporal boundaries from noisy proposals in a denoising diffusion process, conditioned on a target audio sample. During training, our model learns to reverse the noising process by converting noisy latent queries to the ground-truth versions in the elegant Transformer decoder framework. Doing so enables the model generate accurate event boundaries from even noisy queries during inference. Extensive experiments on the Urban-SED and EPIC-Sounds datasets demonstrate that our model significantly outperforms existing alternatives, with 40+% faster convergence in training. Code: https://github.com/Surrey-UPLab/DiffSED","tags":["sound event detection","denoising diffusion","generative learning"],"title":"DiffSED: Sound Event Detection with Denoising Diffusion","type":"publication"},{"authors":["Jaleh Delfani","Constantin Orăsan","Hadeel Saadany","Ozlem Temizoz","Eleanor Taylor-Stilgoe","Diptesh Kanojia","Sabine Braun","Barbara Schouten"],"categories":null,"content":"","date":1707177600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1707177600,"objectID":"80e8be18b23469319d8460256771c553","permalink":"https://dipteshkanojia.co.uk/publication/delfani-etal-2024-google/","publishdate":"2024-02-06T00:00:00Z","relpermalink":"/publication/delfani-etal-2024-google/","section":"publication","summary":"This study explores the use of Google Translate (GT) for translating mental healthcare (MHealth) information and evaluates its accuracy, comprehensibility, and implications for multilingual healthcare communication through analysing GT output in the MHealth domain from English to Persian, Arabic, Turkish, Romanian, and Spanish. Two datasets comprising MHealth information from the UK National Health Service website and information leaflets from The Royal College of Psychiatrists were used. Native speakers of the target languages manually assessed the GT translations, focusing on medical terminology accuracy, comprehensibility, and critical syntactic/semantic errors. GT output analysis revealed challenges in accurately translating medical terminology, particularly in Arabic, Romanian, and Persian. Fluency issues were prevalent across various languages, affecting comprehension, mainly in Arabic and Spanish. Critical errors arose in specific contexts, such as bullet-point formatting, specifically in Persian, Turkish, and Romanian. Although improvements are seen in longer-text translations, there remains a need to enhance accuracy in medical and mental health terminology and fluency, whilst also addressing formatting issues for a more seamless user experience. The findings highlight the need to use customised translation engines for Mhealth translation and the challenges when relying solely on machine-translated medical content, emphasising the crucial role of human reviewers in multilingual healthcare communication.","tags":["machine translation","mental healthcare","multilingual communication","google translate"],"title":"Google Translate Error Analysis for Mental Healthcare Information: Evaluating Accuracy, Comprehensibility, and Implications for Multilingual Healthcare Communication","type":"publication"},{"authors":["Diptesh Kanojia"],"categories":null,"content":"","date":1706745600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706745600,"objectID":"3f94ecf2d529ea4a9113ef868d45b1d4","permalink":"https://dipteshkanojia.co.uk/talk/iet2024-generative-ai-nlp/","publishdate":"2024-02-01T00:00:00Z","relpermalink":"/talk/iet2024-generative-ai-nlp/","section":"talk","summary":"Invited lecture at IET Surrey discussing Generative AI and Natural Language Processing. ChatGPT and other large language models are now publicly available offering new opportunities to apply them to problem-solving, with both pros and cons. Taking a people-centered approach to evaluation, Dr Diptesh Kanojia joined us to explain the challenges in utilizing these models and discuss some solutions to tune/adapt such models in resource-constrained scenarios. His talk is illustrated by applications healthcare clinical report generation, text-attribution in education to detect the source of generated text, followed by an insightful Q\u0026A session with the live audience.","tags":["talks","invited-lecture","generative-ai","natural-language-processing","people-centred-ai"],"title":"Generative AI and Natural Language Processing","type":"talk"},{"authors":["Jay Gala","Thanmay Jayakumar","Jaavid Aktar Husain","Mohammed Safi Ur Rahman Khan","Diptesh Kanojia","Ratish Puduppully","Mitesh M Khapra","Raj Dabre","Rudra Murthy","Anoop Kunchukuttan"],"categories":null,"content":"","date":1706227200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706227200,"objectID":"14ccf5e43a9fe768edd3841fbc3b446d","permalink":"https://dipteshkanojia.co.uk/publication/gala-etal-2024-airavata/","publishdate":"2024-01-26T00:00:00Z","relpermalink":"/publication/gala-etal-2024-airavata/","section":"publication","summary":"","tags":["large language models","instruction tuning","hindi","llm"],"title":"Airavata: Introducing Hindi Instruction-tuned LLM","type":"publication"},{"authors":["Heather Lent","Kushal Tatariya","Raj Dabre","Yiyi Chen","Marcell Fekete","Esther Ploeger","Li Zhou","Ruth-Ann Armstrong","Abee Eijansantos","Catriona Malau","Hans Erik Heje","Ernests Lavrinovics","Diptesh Kanojia","Paul Belony","Marcel Bollmann","Loïc Grobol","Miryam de Lhoneux","Daniel Hershcovich","Michel DeGraff","Anders Søgaard","Johannes Bjerva"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"a0db610bc9ed1435e6ac54f50cba3672","permalink":"https://dipteshkanojia.co.uk/publication/lent-etal-2024-creoleval/","publishdate":"2024-01-01T00:00:00Z","relpermalink":"/publication/lent-etal-2024-creoleval/","section":"publication","summary":"Creoles represent an under-explored and marginalized group of languages, with few available resources for NLP research. While the genealogical ties between Creoles and a number of highly resourced languages imply a significant potential for transfer learning, this potential is hampered due to this lack of annotated data. In this work we present CreoleVal, a collection of benchmark datasets spanning 8 different NLP tasks, covering up to 28 Creole languages; it is an aggregate of novel development datasets for reading comprehension relation classification, and machine translation for Creoles, in addition to a practical gateway to a handful of preexisting benchmarks. For each benchmark, we conduct baseline experiments in a zero-shot setting in order to further ascertain the capabilities and limitations of transfer learning for Creoles. Ultimately, we see CreoleVal as an opportunity to empower research on Creoles in NLP and computational linguistics, and in general, a step towards more equitable language technology around the globe.","tags":["creoles","multilingual","benchmarks","NLP tasks"],"title":"CreoleVal: Multilingual Multitask Benchmarks for Creoles","type":"publication"},{"authors":["Akshay Batheja","Sourabh Deoghare","Diptesh Kanojia","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1703116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1703116800,"objectID":"b9a711c5ffa5ed2eafd408089acf78c9","permalink":"https://dipteshkanojia.co.uk/publication/batheja-etal-2023-ape/","publishdate":"2023-12-21T00:00:00Z","relpermalink":"/publication/batheja-etal-2023-ape/","section":"publication","summary":"Automatic Post-Editing (APE) is the task of automatically identifying and correcting errors in the Machine Translation (MT) outputs. We propose a repair-filter-use methodology that uses an APE system to correct errors on the target side of the MT training data. We select the sentence pairs from the original and corrected sentence pairs based on the quality scores computed using a Quality Estimation (QE) model. To the best of our knowledge, this is a novel adaptation of APE and QE to extract quality parallel corpus from the pseudo-parallel corpus. By training with this filtered corpus, we observe an improvement in the Machine Translation system's performance by 5.64 and 9.91 BLEU points, for English-Marathi and Marathi-English, over the baseline model. The baseline model is the one that is trained on the whole pseudo-parallel corpus. Our work is not limited by the characteristics of English or Marathi languages; and is language pair-agnostic, given the necessary QE and APE data.","tags":["automatic post-editing","quality estimation","machine translation","pseudo-parallel corpora"],"title":"APE-then-QE: Correcting then Filtering Pseudo Parallel Corpora for MT Training Data Creation","type":"publication"},{"authors":["Pushpak Bhattacharyya","Rajen Chatterjee","Markus Freitag","Diptesh Kanojia","Matteo Negri","Marco Turchi"],"categories":null,"content":"","date":1701820800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701820800,"objectID":"8de8d7f2def6eb66fe8fd832afc8eff9","permalink":"https://dipteshkanojia.co.uk/publication/bhattacharyya-2023-wmt-ape-findings/","publishdate":"2023-12-06T00:00:00Z","relpermalink":"/publication/bhattacharyya-2023-wmt-ape-findings/","section":"publication","summary":"We present the results from the 9th round of the WMT shared task on MT Automatic Post-Editing, which consists of automatically correcting the output of a “black-box” machine translation system by learning from human corrections. Like last year, the task focused on English→Marathi, with data coming from multiple domains (healthcare, tourism, and general/news). Despite the consistent task framework, this year’s data proved to be extremely challenging. As a matter of fact, none of the official submissions from the participating teams succeeded in improving the quality of the already high-level initial translations (with baseline TER and BLEU scores of 26.6 and 70.66, respectively). Only one run, accepted as a “late” submission, achieved automatic evaluation scores that exceeded the baseline.","tags":["automatic post-editing","machine translation","shared task","findings"],"title":"Findings of the WMT 2023 Shared Task on Automatic Post-Editing","type":"publication"},{"authors":["Frederic Blain","Chrysoula Zerva","Ricardo Rei","Nuno M. Guerreiro","Diptesh Kanojia","José G. C. de Souza","Beatriz Silva","Tânia Vaz","Yan Jingxuan","Fatemeh Azadi","Constantin Orăsan","André Martins"],"categories":null,"content":"","date":1701820800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701820800,"objectID":"f70463ac2f27707efc43a692898df022","permalink":"https://dipteshkanojia.co.uk/publication/blain-etal-2023-findings/","publishdate":"2023-12-06T00:00:00Z","relpermalink":"/publication/blain-etal-2023-findings/","section":"publication","summary":"We report the results of the WMT 2023 shared task on Quality Estimation, in which the challenge is to predict the quality of the output of neural machine translation systems at the word and sentence levels, without access to reference translations. This edition introduces a few novel aspects and extensions that aim to enable more fine-grained, and explainable quality estimation approaches. We introduce an updated quality annotation scheme using Multidimensional Quality Metrics to obtain sentence- and word-level quality scores for three language pairs. We also extend the provided data to new language pairs: we specifically target low-resource languages and provide training, development and test data for English-Hindi, English-Tamil, English-Telegu and English-Gujarati as well as a zero-shot test-set for English-Farsi. Further, we introduce a novel fine-grained error prediction task aspiring to motivate research towards more detailed quality predictions.","tags":["quality estimation","machine translation","shared task","low-resource languages"],"title":"Findings of the WMT 2023 Shared Task on Quality Estimation","type":"publication"},{"authors":["Divyank Tiwari","Diptesh Kanojia","Anupama Ray","Apoorva Nunna","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1701820800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701820800,"objectID":"1d92a59f704d6b51e50ce87b1ace3e00","permalink":"https://dipteshkanojia.co.uk/publication/tiwari-etal-2023-predict/","publishdate":"2023-12-06T00:00:00Z","relpermalink":"/publication/tiwari-etal-2023-predict/","section":"publication","summary":"Sarcasm is a complex linguistic construct with incongruity at its very core. Detecting sarcasm depends on the actual content spoken and tonality, facial expressions, the context of an utterance, and personal traits like language proficiency and cognitive capabilities. In this paper, we propose the utilization of synthetic gaze data to improve the task performance for multimodal sarcasm detection in a conversational setting. We enrich an existing multimodal conversational dataset, i.e., MUStARD++ with gaze features. With the help of human participants, we collect gaze features for 20% of data instances, and we investigate various methods for gaze feature prediction for the rest of the dataset. We perform extrinsic and intrinsic evaluations to assess the quality of the predicted gaze features. We observe a performance gain of up to 6.6% points by adding a new modality, i.e., collected gaze features. When both collected and predicted data are used, we observe a performance gain of 2.3% points on the complete dataset. Interestingly, with only predicted gaze features, too, we observe a gain in performance (1.9% points). We retain and use the feature prediction model, which maximally correlates with collected gaze features. Our model trained on combining collected and synthetic gaze data achieves SoTA performance on the MUStARD++ dataset. To the best of our knowledge, ours is the first predict-and-use model for sarcasm detection. We publicly release the code, gaze data, and our best models for further research.","tags":["sarcasm detection","multimodal","gaze prediction","machine learning"],"title":"Predict and Use: Harnessing Predicted Gaze to Improve Multimodal Sarcasm Detection","type":"publication"},{"authors":["Sourabh Deoghare","Diptesh Kanojia","Fred Blain","Tharindu Ranasinghe","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1701820800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701820800,"objectID":"1bc41ebd532ec7c1d827b8c1bcf14c30","permalink":"https://dipteshkanojia.co.uk/publication/deoghare-etal-2023-quality/","publishdate":"2023-12-06T00:00:00Z","relpermalink":"/publication/deoghare-etal-2023-quality/","section":"publication","summary":"Automatic Post-Editing (APE) systems are prone to over-correction of the Machine Translation (MT) outputs. While Word-level Quality Estimation (QE) system can provide a way to curtail the over-correction, a significant performance gain has not been observed thus far by utilizing existing APE and QE combination strategies. In this paper, we propose joint training of a model on APE and QE tasks to improve the APE. Our proposed approach utilizes a multi-task learning (MTL) methodology, which shows significant improvement while treating both tasks as a 'bargaining game' during training. Moreover, we investigate various existing combination strategies and show that our approach achieves state-of-the-art performance for a 'distant' language pair, viz., English-Marathi. We observe an improvement of 1.09 TER and 1.37 BLEU points over a baseline QE-Unassisted APE system for English-Marathi, while also observing 0.46 TER and 0.62 BLEU points for English-German. Further, we discuss the results qualitatively and show how our approach helps reduce over-correction, thereby improving the APE performance. We also observe that the degree of integration between QE and APE directly correlates with the APE performance gain. We release our code and models publicly.","tags":["automatic post-editing","quality estimation","machine translation","multi-task learning"],"title":"Quality Estimation-Assisted Automatic Post-Editing","type":"publication"},{"authors":["Archchana Sindhujan","Diptesh Kanojia","Constantin Orăsan","Tharindu Ranasinghe"],"categories":null,"content":"","date":1701820800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701820800,"objectID":"ad1af1b08078155707d3c9a8f5defe7a","permalink":"https://dipteshkanojia.co.uk/publication/sindhujan-etal-2023-surreyai/","publishdate":"2023-12-06T00:00:00Z","relpermalink":"/publication/sindhujan-etal-2023-surreyai/","section":"publication","summary":"Quality Estimation (QE) systems are important in situations where it is necessary to assess the quality of translations, but there is no reference available. This paper describes the approach adopted by the SurreyAI team for addressing the Sentence-Level Direct Assessment shared task in WMT23. The proposed approach builds upon the TransQuest framework, exploring various autoencoder pre-trained language models within the MonoTransQuest architecture using single and ensemble settings. The autoencoder pre-trained language models employed in the proposed systems are XLMV, InfoXLM-large, and XLMR-large. The evaluation utilizes Spearman and Pearson correlation coefficients, assessing the relationship between machine-predicted quality scores and human judgments for 5 language pairs (English-Gujarati, English-Hindi, English-Marathi, English-Tamil and English-Telugu). The MonoTQ-InfoXLM-large approach emerges as a robust strategy, surpassing all other individual models proposed in this study by significantly improving over the baseline for the majority of the language pairs.","tags":["quality estimation","machine translation","shared task","transquest"],"title":"SurreyAI 2023 Submission for the Quality Estimation Shared Task","type":"publication"},{"authors":["Swapnil Bhosale","Abhra Chaudhuri","Alex Lee Robert Williams","Divyank Tiwari","Anjan Dutta","Xiatian Zhu","Pushpak Bhattacharyya","Diptesh Kanojia"],"categories":null,"content":"","date":1696291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696291200,"objectID":"624e02b98d9358138e2235c765c920e2","permalink":"https://dipteshkanojia.co.uk/publication/bhosale-etal-2023-sarcasm/","publishdate":"2023-10-03T00:00:00Z","relpermalink":"/publication/bhosale-etal-2023-sarcasm/","section":"publication","summary":"The introduction of the MUStARD dataset, and its emotion recognition extension MUStARD++, have identified sarcasm to be a multi-modal phenomenon -- expressed not only in natural language text, but also through manners of speech (like tonality and intonation) and visual cues (facial expression). With this work, we aim to perform a rigorous benchmarking of the MUStARD++ dataset by considering state-of-the-art language, speech, and visual encoders, for fully utilizing the totality of the multi-modal richness that it has to offer, achieving a 2% improvement in macro-F1 over the existing benchmark. Additionally, to cure the imbalance in the 'sarcasm type' category in MUStARD++, we propose an extension, which we call \\emph{MUStARD++ Balanced}, benchmarking the same with instances from the extension split across both train and test sets, achieving a further 2.4% macro-F1 boost. The new clips were taken from a novel source -- the TV show, House MD, which adds to the diversity of the dataset, and were manually annotated by multiple annotators with substantial inter-annotator agreement in terms of Cohen's kappa and Krippendorf's alpha. Our code, extended data, and SOTA benchmark models are made public.","tags":["sarcasm detection","multimodal","benchmarking"],"title":"Sarcasm in Sight and Sound: Benchmarking and Expansion to Improve Multimodal Sarcasm Detection","type":"publication"},{"authors":["Diptesh Kanojia"],"categories":null,"content":"","date":1696114800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696114800,"objectID":"ea99c24136dd173b39ddab2d6af9e529","permalink":"https://dipteshkanojia.co.uk/talk/ebay2023-efficient-explainable-ir/","publishdate":"2023-10-01T00:00:00+01:00","relpermalink":"/talk/ebay2023-efficient-explainable-ir/","section":"talk","summary":"Keynote speaker at eBay Tech day discussing Efficient and Explainable Information Retrieval.","tags":["talks","keynote","information-retrieval","explainability","efficiency"],"title":"Efficient and Explainable Information Retrieval","type":"talk"},{"authors":["Shenbin Qian","Constantin Orăsan","Félix do Carmo","Diptesh Kanojia"],"categories":null,"content":"","date":1694995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1694995200,"objectID":"b9cc8735343f0f2c862436358f2b8d2e","permalink":"https://dipteshkanojia.co.uk/publication/qian-etal-2023-challenges/","publishdate":"2023-09-18T00:00:00Z","relpermalink":"/publication/qian-etal-2023-challenges/","section":"publication","summary":"This paper attempts to identify challenges professional translators face when translating emotion-loaded texts as well as errors machine translation (MT) makes when translating this content. We invited ten Chinese-English translators to translate thirty posts of a Chinese microblog, and interviewed them about the challenges encountered during translation and the problems they believe MT might have. Further, we analysed more than five-thousand automatic translations of microblog posts to observe problems in MT outputs. We establish that the most challenging problem for human translators is emotion-carrying words, which translators also consider as a problem for MT. Analysis of MT outputs shows that this is also the most common source of MT errors. We also find that what is challenging for MT, such as non-standard writing, is not necessarily an issue for humans. Our work contributes to a better understanding of the challenges for the translation of microblog posts by humans and MT, caused by different forms of expression of emotion.","tags":["machine translation","emotion translation","human translation","chinese microblog"],"title":"Challenges of Human vs Machine Translation of Emotion-Loaded Chinese Microblog Texts","type":"publication"},{"authors":["Swapnil Bhosale","Haosen Yang","Diptesh Kanojia","Xiatian Zhu"],"categories":null,"content":"","date":1694476800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1694476800,"objectID":"9b86bc6ee9659907a543ab5a2b122b92","permalink":"https://dipteshkanojia.co.uk/publication/bhosale-etal-2023-leveraging/","publishdate":"2023-09-12T00:00:00Z","relpermalink":"/publication/bhosale-etal-2023-leveraging/","section":"publication","summary":"Audio-Visual Segmentation (AVS) aims to precisely outline audible objects in a visual scene at the pixel level. Existing AVS methods require fine-grained annotations of audio-mask pairs in supervised learning fashion. This limits their scalability since it is time consuming and tedious to acquire such cross-modality pixel level labels. To overcome this obstacle, in this work we introduce unsupervised audio-visual segmentation with no need for task-specific data annotations and model training. For tackling this newly proposed problem, we formulate a novel Cross-Modality Semantic Filtering (CMSF) approach to accurately associate the underlying audio-mask pairs by leveraging the off-the-shelf multi-modal foundation models (e.g., detection [1], open-world segmentation [2] and multi-modal alignment [3]). Guiding the proposal generation by either audio or visual cues, we design two training-free variants: AT-GDINO-SAM and OWOD-BIND. Extensive experiments on the AVS-Bench dataset show that our unsupervised approach can perform well in comparison to prior art supervised counterparts across complex scenarios with multiple auditory objects. Particularly, in situations where existing supervised AVS methods struggle with overlapping foreground objects, our models still excel in accurately segmenting overlapped auditory objects. Our code will be publicly released.","tags":["audio-visual segmentation","foundation models","unsupervised learning"],"title":"Leveraging Foundation Models for Unsupervised Audio-Visual Segmentation","type":"publication"},{"authors":["Akash Rawat","Nazia Nafis","Dnyaneshwar Bhadane","Diptesh Kanojia","Rudra Murthy"],"categories":null,"content":"","date":1689206400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689206400,"objectID":"33e253ac288f04499c74f7bced6abee2","permalink":"https://dipteshkanojia.co.uk/publication/rawat-2023-modelling-political-aggression/","publishdate":"2023-07-13T00:00:00Z","relpermalink":"/publication/rawat-2023-modelling-political-aggression/","section":"publication","summary":"Recent years have seen a proliferation of aggressive social media posts, often wreaking even real-world consequences for victims. Aggressive behaviour on social media is especially evident during important sociopolitical events such as elections, communal incidents, and public protests. In this paper, we introduce a dataset in English to model political aggression. The dataset comprises public tweets collated across the time-frames of two of the most recent Indian general elections. We manually annotate this data for the task of aggression detection and analyze this data for aggressive behaviour. To benchmark the efficacy of our dataset, we perform experiments by fine-tuning pre-trained language models and comparing the results with models trained on an existing but general domain dataset. Our models consistently outperform the models trained on existing data. Our best model achieves a macro F1-score of 66.66 on our dataset. We also train models on a combined version of both datasets, achieving best macro F1-score of 92.77, on our dataset. Additionally, we create subsets of code-mixed and non-code-mixed data from the combined dataset to observe variations in results due to the Hindi-English code-mixing phenomenon. We publicly release the anonymized data, code, and models for further research.","tags":["political aggression","social media","sentiment analysis","aggression detection"],"title":"Modelling Political Aggression on Social Media Platforms","type":"publication"},{"authors":["Nazia Nafis","Diptesh Kanojia","Naveen Saini","Rudra Murthy"],"categories":null,"content":"","date":1689206400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689206400,"objectID":"12c741d94e219c7254d2ffdb576a5542","permalink":"https://dipteshkanojia.co.uk/publication/nafis-etal-2023-towards/","publishdate":"2023-07-13T00:00:00Z","relpermalink":"/publication/nafis-etal-2023-towards/","section":"publication","summary":"Cyberbullying is a serious societal issue widespread on various channels and platforms, particularly social networking sites. Such platforms have proven to be exceptionally fertile grounds for such behavior. The dearth of high-quality training data for multilingual and low-resource scenarios, data that can accurately capture the nuances of social media conversations, often poses a roadblock to this task. This paper attempts to tackle cyberbullying, specifically its two most common manifestations - aggression and offensiveness. We present a novel, manually annotated dataset of a total of 10,000 English and Hindi-English code-mixed tweets, manually annotated for aggression detection and offensive language detection tasks. Our annotations are supported by inter-annotator agreement scores of 0.67 and 0.74 for the two tasks, indicating substantial agreement. We perform comprehensive fine-tuning of pre-trained language models (PTLMs) using this dataset to check its efficacy. Our challenging test sets show that the best models achieve macro F1-scores of 67.87 and 65.45 on the two tasks, respectively. Further, we perform cross-dataset transfer learning to benchmark our dataset against existing aggression and offensive language datasets. We also present a detailed quantitative and qualitative analysis of errors in prediction, and with this paper, we publicly release the novel dataset, code, and models.","tags":["cyberbullying","aggression detection","offensive language","code-mixed tweets"],"title":"Towards Safer Communities: Detecting Aggression and Offensive Language in Code-Mixed Tweets to Combat Cyberbullying","type":"publication"},{"authors":["Sourabh Deoghare","Paramveer Choudhary","Diptesh Kanojia","Tharindu Ranasinghe","Pushpak Bhattacharyya","Constantin Orăsan"],"categories":null,"content":"","date":1688860800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688860800,"objectID":"553789ad299693e6be9d5f119edae938","permalink":"https://dipteshkanojia.co.uk/publication/deoghare-etal-2023-multi/","publishdate":"2023-07-09T00:00:00Z","relpermalink":"/publication/deoghare-etal-2023-multi/","section":"publication","summary":"Quality Estimation (QE) is the task of evaluating machine translation output in the absence of reference translation. Conventional approaches to QE involve training separate models at different levels of granularity viz., word-level, sentence-level, and document-level, which sometimes lead to inconsistent predictions for the same input. To overcome this limitation, we focus on jointly training a single model for sentence-level and word-level QE tasks in a multi-task learning framework. Using two multi-task learning-based QE approaches, we show that multi-task learning improves the performance of both tasks. We evaluate these approaches by performing experiments in different settings, viz., single-pair, multi-pair, and zero-shot. We compare the multi-task learning-based approach with baseline QE models trained on single tasks and observe an improvement of up to 4.28% in Pearson's correlation (r) at sentence-level and 8.46% in F1-score at word-level, in the single-pair setting. In the multi-pair setting, we observe improvements of up to 3.04% at sentence-level and 13.74% at word-level; while in the zero-shot setting, we also observe improvements of up to 5.26% and 3.05%, respectively. We make the models proposed in this paper publically available.","tags":["quality estimation","machine translation","multi-task learning"],"title":"A Multi-task Learning Framework for Quality Estimation","type":"publication"},{"authors":["Shenbin Qian","Constantin Orăsan","Felix Do Carmo","Qiuliang Li","Diptesh Kanojia"],"categories":null,"content":"","date":1686528000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686528000,"objectID":"f501443c69e9a5ff6264748050c9537f","permalink":"https://dipteshkanojia.co.uk/publication/qian-2023-evaluation-chinese-english-mt/","publishdate":"2023-06-12T00:00:00Z","relpermalink":"/publication/qian-2023-evaluation-chinese-english-mt/","section":"publication","summary":"In this paper, we focus on how current Machine Translation (MT) engines perform on the translation of emotion-loaded texts by evaluating outputs from Google Translate according to a framework proposed in this paper. We propose this evaluation framework based on the Multidimensional Quality Metrics (MQM) and perform detailed error analyses of the MT outputs. From our analysis, we observe that about 50% of MT outputs are erroneous in preserving emotions. After further analysis of the erroneous examples, we find that emotion carrying words and linguistic phenomena such as polysemous words, negation, abbreviation etc., are common causes for these translation errors.","tags":["machine translation","emotion translation","quality assessment","chinese-english"],"title":"Evaluation of Chinese-English Machine Translation of Emotion-Loaded Microblog Texts: A Human Annotated Dataset for the Quality Assessment of Emotion Translation","type":"publication"},{"authors":["Diptesh Kanojia"],"categories":null,"content":"","date":1675512000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675512000,"objectID":"ac61c14f6d688f4b07dd14b3a7fe3aa2","permalink":"https://dipteshkanojia.co.uk/talk/convposter/","publishdate":"2023-02-04T12:00:00Z","relpermalink":"/talk/convposter/","section":"talk","summary":"This was a poster I presented at [Convergence 2023](https://www.surrey.ac.uk/centre-translation-studies/convergence-2023). I discuss the work done, the collaborations, our NLP Cafe and publicly available resouces for NLP research contributed by Surrey-NLP.","tags":["natural language processing","nlp"],"title":"Advances in Natural Language Processing @ Surrey","type":"talk"},{"authors":["Diptesh Kanojia"],"categories":null,"content":"","date":1675512000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675512000,"objectID":"b5ac4c5a1e7b9c35d223698cdd4718ea","permalink":"https://dipteshkanojia.co.uk/talk/convworkshopnmt/","publishdate":"2023-02-04T12:00:00Z","relpermalink":"/talk/convworkshopnmt/","section":"talk","summary":"The workshop explored questions on the lines of how should knowledge about neural machine translation be disseminated in the translator/interpreter community, what is the preferred approach, and how detailed should it be. The presented is just one of the approaches to take when NMT is briefly introduced. Presented at the workshop, '[Teaching Neural Machine Translation to Translators](https://www.surrey.ac.uk/centre-translation-studies/convergence-2023/workshop-teaching-neural-machine-translation-translators)' at [Convergence 2023](https://www.surrey.ac.uk/centre-translation-studies/convergence-2023).","tags":["talks","machine translation","neural machine translation","translators"],"title":"Workshop: Teaching Neural Machine Translation to Translators","type":"talk"},{"authors":["Diptesh Kanojia"],"categories":null,"content":"","date":1675468800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675468800,"objectID":"a29c05286d6b520e3564e529942b1c8b","permalink":"https://dipteshkanojia.co.uk/talk/convpaneltalk/","publishdate":"2023-02-04T00:00:00Z","relpermalink":"/talk/convpaneltalk/","section":"talk","summary":"Presented as a co-chair on the panel, '[Natural Language Processing Augmenting Translation and Interpreting](https://www.surrey.ac.uk/centre-translation-studies/convergence-2023/nlp-augmenting-translation-and-interpreting)' at [Convergence 2023](https://www.surrey.ac.uk/centre-translation-studies/convergence-2023). The slide deck discusses in brief our investigations in the Quality Estimation area; has some details on future directions as well.","tags":["multilingual","multilinguality","nlp","qualityestimation","machinetranslation","neuralmachinetranslation"],"title":"Quality Estimation for Machine Translation","type":"talk"},{"authors":["Diptesh Kanojia","Aditya Joshi"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"e4859d5578d331fea31a4daa9d6fce20","permalink":"https://dipteshkanojia.co.uk/publication/kanojia-joshi-2023-applications/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/publication/kanojia-joshi-2023-applications/","section":"publication","summary":"Sentiment analysis has benefited from the availability of lexicons and benchmark datasets created over decades of research. However, its applications to the real world are a driving force for research in SA. This chapter describes some of these applications and related challenges in real-life scenarios. In this chapter, we focus on five applications of SA: health, social policy, e-commerce, digital humanities and other areas of NLP. This chapter is intended to equip an NLP researcher with the 'what', 'why' and 'how' of applications of SA: what is the application about, why it is important and challenging and how current research in SA deals with the application. We note that, while the use of deep learning techniques is a popular paradigm that spans these applications, challenges around privacy and selection bias of datasets is a recurring theme across several applications.","tags":["sentiment analysis","applications","real-life scenarios"],"title":"Applications and Challenges of Sentiment Analysis in Real-life Scenarios","type":"publication"},{"authors":["Pushpak Bhattacharyya","Rajen Chatterjee","Markus Freitag","Diptesh Kanojia","Matteo Negri","Marco Turchi"],"categories":null,"content":"","date":1670371200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670371200,"objectID":"6d058c8d803076ef991d5a54cac2f0af","permalink":"https://dipteshkanojia.co.uk/publication/wmt-2022-findings-ape/","publishdate":"2022-12-07T00:00:00Z","relpermalink":"/publication/wmt-2022-findings-ape/","section":"publication","summary":"We present the results from the 8th round of the WMT shared task on MT Automatic Post-Editing, which consists in automatically correcting the output of a 'black-box' machine translation system by learning from human corrections. This year, the task focused on a new language pair (English→Marathi) and on data coming from multiple domains (healthcare, tourism, and general/news). Although according to several indicators this round was of medium-high difficulty compared to the past, the best submission from the three participating teams managed to significantly improve (with an error reduction of 3.49 TER points) the original translations produced by a generic neural MT system.","tags":["automatic post-editing","APE","English-Marathi","low-resource","post-machine-translation"],"title":"Findings of the WMT 2022 Shared Task on Automatic Post-Editing","type":"publication"},{"authors":["Chrysoula Zerva","Frédéric Blain","Ricardo Rei","Piyawat Lertvittayakumjorn","José G. C. de Souza","Steffen Eger","Diptesh Kanojia","Duarte Alves","Constantin Orăsan","Marina Fomicheva","André F. T. Martins","Lucia Specia"],"categories":null,"content":"","date":1670371200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670371200,"objectID":"a201c5495998d3c0e134336d7dcff8dc","permalink":"https://dipteshkanojia.co.uk/publication/wmt-2022-findings-qe/","publishdate":"2022-12-07T00:00:00Z","relpermalink":"/publication/wmt-2022-findings-qe/","section":"publication","summary":"We report the results of the WMT 2022 shared task on Quality Estimation, in which the challenge is to predict the quality of the output of neural machine translation systems at the word and sentence levels, without access to reference translations. This edition introduces a few novel aspects and extensions that aim to enable more fine-grained, and explainable quality estimation approaches. We introduce an updated quality annotation scheme using Multidimensional Quality Metrics to obtain sentence- and word-level quality scores for three language pairs. We also extend the Direct Assessments and post-edit data (MLQE-PE) to new language pairs: we present a novel and large dataset on English-Marathi, as well as a zero-shot test-set on English-Yoruba. Further, we include an explainability sub-task for all language pairs and present a new format of a critical error detection task for two new language pairs. Participants from 11 different teams submitted altogether 991 systems to different task variants and language pair.","tags":["quality estimation","evaluation","low-resource","QE","post-machine-translation"],"title":"Findings of the WMT 2022 Shared Task on Quality Estimation","type":"publication"},{"authors":["Jordan Painter","Helen Treharne","Diptesh Kanojia"],"categories":null,"content":"","date":1670371200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670371200,"objectID":"97dbf1d360a5c491310b27bfe76b063f","permalink":"https://dipteshkanojia.co.uk/publication/nlpcss-emnlp-2022-sarcasm/","publishdate":"2022-12-07T00:00:00Z","relpermalink":"/publication/nlpcss-emnlp-2022-sarcasm/","section":"publication","summary":"Sarcasm is prevalent in all corners of social media, posing many challenges within Natural Language Processing (NLP), particularly for sentiment analysis. Sarcasm detection remains a largely unsolved problem in many NLP tasks due to its contradictory and typically derogatory nature as a figurative language construct. With recent strides in NLP, many pre-trained language models exist that have been trained on data from specific social media platforms, i.e., Twitter. In this paper, we evaluate the efficacy of multiple sarcasm detection datasets using machine and deep learning models. We create two new datasets - a manually annotated gold standard Sarcasm Annotated Dataset (SAD) and a Silver-Standard Sarcasm-annotated Dataset (S3D). Using a combination of existing sarcasm datasets with SAD, we train a sarcasm detection model over a social-media domain pre-trained language model, BERTweet, which yields an F1-score of 78.29%. Using an Ensemble model with an underlying majority technique, we further label S3D to produce a weakly supervised dataset containing over 100,000 tweets. We publicly release all the code, our manually annotated and weakly supervised datasets, and fine-tuned models for further research.","tags":["sarcasm detection","sarcasm prediction","discourse","sentiment","weak supervision","dataset"],"title":"Utilizing Weak Supervision to Create S3D: A Sarcasm Annotated Dataset","type":"publication"},{"authors":["Diptesh Kanojia"],"categories":null,"content":"","date":1669334400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669334400,"objectID":"3b074c9d00c6cbea4bf39a1010e1e662","permalink":"https://dipteshkanojia.co.uk/talk/cmcbseminar/","publishdate":"2022-11-25T00:00:00Z","relpermalink":"/talk/cmcbseminar/","section":"talk","summary":"In this talk, I discuss the interdisciplinary area cognitive NLP. I discuss the various intersections which give it a unique blend and discuss the basics of research based on eye-tracking and NLP. Further, I try to illustrate the nitty-gritties of this research with an illustrative example of our work published in 2021, 'Cognition-aware Cognate Detection'.","tags":["talks","cognitive-nlp","cognate detection","transformers"],"title":"Cognitive Natural Language Processing","type":"talk"},{"authors":["Diptesh Kanojia"],"categories":null,"content":"","date":1668470400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668470400,"objectID":"63ed61d58d004149838dbd3b208a3760","permalink":"https://dipteshkanojia.co.uk/talk/kitguestlec/","publishdate":"2022-11-15T00:00:00Z","relpermalink":"/talk/kitguestlec/","section":"talk","summary":"In this talk, I discuss the Quality Estimation (QE) for Machine Translation (MT). I discuss the basics of the QE task, and the QE shared task organized every year. Further, the discussion get into how current MT systems achieve very good results on a growing variety of language pairs and datasets. However, they are known to produce fluent translation outputs that can contain important meaning errors, thus undermining their reliability in practice. Quality Estimation (QE) is the task of automatically assessing the performance of MT systems at test time. Thus, in order to be useful, QE systems should be able to detect such errors. However, this ability is yet to be tested in the current evaluation practices, where QE systems are assessed only in terms of their correlation with human judgements. In this talk, we will discuss how we attempted to bridge this gap by proposing a general methodology for the adversarial testing of QE for MT. In this discussion, we first see that despite a high correlation with human judgements achieved by the recent SOTA, certain types of meaning errors are still problematic for QE to detect. We also discuss how the ability of a given model to discriminate between meaning-preserving and meaning-altering perturbations is predictive of its overall performance, thus potentially allowing us to compare the QE systems without relying on manual quality annotation.","tags":["talks","quality estimation","machine translation","adversarial evaluation","probing systems"],"title":"Quality Estimation","type":"talk"},{"authors":["Diptesh Kanojia"],"categories":null,"content":"","date":1663331400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663331400,"objectID":"1d7f82ddd3fbb83e9e169985512076a9","permalink":"https://dipteshkanojia.co.uk/talk/lithmetalk/","publishdate":"2022-09-16T13:30:00+01:00","relpermalink":"/talk/lithmetalk/","section":"talk","summary":"In this invited talk to the [LITHME WG8](https://lithme.eu/working-groups/wg8/) meeting, I gave an introduction to chatbots and its basic building blocks. We discussed the role of fundamental NLP tasks in chatbots and how they can be used to build a chatbot. I also discussed the various challenges in building a chatbot and how to overcome them.","tags":["talks","chatbots","ner","intent classification"],"title":"Dialouge Processing: The role of NLP and building blocks of a chatbot","type":"talk"},{"authors":["Varad Bhatnagar","Diptesh Kanojia","Kameswari Chebrolu"],"categories":null,"content":"","date":1662854400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1662854400,"objectID":"2935ffd203f01f1d71d60e2680ae4996","permalink":"https://dipteshkanojia.co.uk/publication/coling-2022-factcheck/","publishdate":"2022-09-11T00:00:00Z","relpermalink":"/publication/coling-2022-factcheck/","section":"publication","summary":"Social media platforms have become new battlegrounds for anti-social elements, with misinformation being the weapon of choice. Fact-checking organizations try to debunk as many claims as possible while staying true to their journalistic processes but cannot cope with its rapid dissemination. We believe that the solution lies in partial automation of the fact-checking life cycle, saving human time for tasks which require high cognition. We propose a new workflow for efficiently detecting previously fact-checked claims that uses abstractive summarization to generate crisp queries. These queries can then be executed on a general-purpose retrieval system associated with a collection of previously fact-checked claims. We curate an abstractive text summarization dataset comprising noisy claims from Twitter and their gold summaries. It is shown that retrieval performance improves 2x by using popular out-of-the-box summarization models and 3x by fine-tuning them on the accompanying dataset compared to verbatim querying. Our approach achieves Recall@5 and MRR of 35% and  0.3, compared to baseline values of 10% and 0.1, respectively. Our dataset, code, and models are available publicly [here](https://github.com/varadhbhatnagar/FC-Claim-Det/). ","tags":["fact-checking","google fact check","automatic pipeline","abstractive summarization","twitter data","social media","misinformation"],"title":"Harnessing Abstractive Summarization for Fact-Checked Claim Detection","type":"publication"},{"authors":["Diptesh Kanojia"],"categories":null,"content":"","date":1660086000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660086000,"objectID":"e166686cc58131bb506cf4592baddd96","permalink":"https://dipteshkanojia.co.uk/talk/cvssptalk/","publishdate":"2022-08-10T00:00:00+01:00","relpermalink":"/talk/cvssptalk/","section":"talk","summary":"In this talk, I discuss the Transformers architecture in some detail along with the evolution of embeddings in the NLP sub-area of AI. The talk also features various other architectures and example of the fine tuning process. Some slides have been redacted as they are ongoing investigations in our research group. These were presented internally at the University.","tags":["talks","transformers","bert","attention"],"title":"Transformers: Perspectives from NLP","type":"talk"},{"authors":["Rudra Murthy","Pallab Bhattacharjee","Rahul Sharnagat","Jyotsana Khatri","Diptesh Kanojia","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1656028800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656028800,"objectID":"bb9182a1ab2aa7740c482e44e274966c","permalink":"https://dipteshkanojia.co.uk/publication/lrec-2022-hiner/","publishdate":"2022-06-24T00:00:00Z","relpermalink":"/publication/lrec-2022-hiner/","section":"publication","summary":"Named Entity Recognition (NER) is a foundational NLP task that aims to provide class labels like Person, Location, Organisation, Time, and Number to words in free text. Named Entities can also be multi-word expressions where the additional I-O-B annotation information helps label them during the NER annotation process. While English and European languages have considerable annotated data for the NER task, Indian languages lack on that front- both in terms of quantity and following annotation standards. This paper releases a significantly sized standard-abiding Hindi NER dataset containing 109,146 sentences and 2,220,856 tokens, annotated with 11 tags. We discuss the dataset statistics in all their essential detail and provide an in-depth analysis of the NER tag-set used with our data. The statistics of tag-set in our dataset show a healthy per-tag distribution, especially for prominent classes like Person, Location and Organisation. Since the proof of resource-effectiveness is in building models with the resource and testing the model on benchmark data and against the leader-board entries in shared tasks, we do the same with the aforesaid data. We use different language models to perform the sequence labelling task for NER and show the efficacy of our data by performing a comparative evaluation with models trained on another dataset available for the Hindi NER task. Our dataset helps achieve a weighted F1 score of 88.78 with all the tags and 92.22 when we collapse the tag-set, as discussed in the paper. To the best of our knowledge, no available dataset meets the standards of volume (amount) and variability (diversity), as far as Hindi NER is concerned. We fill this gap through this work, which we hope will significantly help NLP for Hindi. We release this dataset with our code and models for further research.","tags":["named entity recognition","transfer learning","NER","Hindi NER","dataset","empirical","evaluation"],"title":"HiNER: A Large Hindi Named Entity Recognition Dataset","type":"publication"},{"authors":["Leonardo Zilio","Hadeel Saadany","Prashant Sharma","Diptesh Kanojia","Constantin Orăsan"],"categories":null,"content":"","date":1656028800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656028800,"objectID":"b81841389e292c892039aa0d3111c9e9","permalink":"https://dipteshkanojia.co.uk/publication/lrec-2022-plod/","publishdate":"2022-06-24T00:00:00Z","relpermalink":"/publication/lrec-2022-plod/","section":"publication","summary":"The detection and extraction of abbreviations from unstructured texts can help to improve the performance of Natural Language Processing tasks, such as machine translation and information retrieval. However, in terms of publicly available datasets, there is not enough data for training deep-neural-networks-based models to the point of generalising well over data. This paperpresents PLOD, a large-scale dataset for abbreviation detection and extraction that contains 160k+ segments automatically annotated with abbreviations and their long forms. We performed manual validation over a set of instances and a complete automatic validation for this dataset. We then used it to generate several baseline models for detecting abbreviations and long forms. The best models achieved an F1-score of 0.92 for abbreviations and 0.89 for detecting their corresponding long forms. We release this dataset along with our code and all the models publicly in this Github Repository.","tags":["abbreviation detection","token classification","abbreviations","scientific","domain-specific","dataset","evaluation","acronym detection"],"title":"PLOD: An Abbreviation Detection Dataset for Scientific Documents","type":"publication"},{"authors":["Shenbin Qian","Constantin Orăsan","Diptesh Kanojia","Hadeel Saadany","Félix Do Carmo"],"categories":null,"content":"","date":1653609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653609600,"objectID":"e338e8352d3af32edf9dd4ca97a55db4","permalink":"https://dipteshkanojia.co.uk/publication/wassa-2022-emotion/","publishdate":"2022-05-27T00:00:00Z","relpermalink":"/publication/wassa-2022-emotion/","section":"publication","summary":"This paper summarises the submissions our team, SURREY-CTS-NLP has made for the WASSA 2022 Shared Task for the prediction of empathy, distress and emotion. In this work, we tested different learning strategies, like ensemble learning and multi-task learning, as well as several large language models, but our primary focus was on analysing and extracting emotion-intensive features from both the essays in the training data and the news articles, to better predict empathy and distress scores from the perspective of discourse and sentiment analysis. We propose several text feature extraction schemes to compensate the small size of training examples for fine-tuning pretrained language models, including methods based on Rhetorical Structure Theory (RST) parsing, cosine similarity and sentiment score. Our best submissions achieve an average Pearson correlation score of 0.518 for the empathy prediction task and an F1 score of 0.571 for the emotion prediction task, indicating that using these schemes to extract emotion-intensive information can help improve model performance.","tags":["emotion recognition","empathy prediction","discourse","sentiment","shared-task"],"title":"SURREY-CTS-NLP at WASSA2022: An Experiment of Discourse and Sentiment Analysis for the Prediction of Empathy, Distress and Emotion","type":"publication"},{"authors":["Diptesh Kanojia"],"categories":null,"content":"","date":1646395200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646395200,"objectID":"5eb8696c81f8293440a1460b90e0c6de","permalink":"https://dipteshkanojia.co.uk/talk/nmttalk/","publishdate":"2022-03-04T12:00:00Z","relpermalink":"/talk/nmttalk/","section":"talk","summary":"Should translators understand the power of the technology behind Google Translate and other providers of machine translation? We think so, and that is why we prepared this webinar as the first step in helping translators make informed decisions when working with this technology. The volume and quality of machine translation produced today baffles anyone who has been working or wants to start working with translation. Neural machine translation (NMT) is a set of the most advanced machine learning technologies that has been yielding surprising volumes of high-quality machine translation output. NMT uses neural network-based models to learn probabilistic models of languages, in such a way that they can be used to estimate very likely good translations of new source sentences. One of the key benefits of these approaches is to simplify the process of training MT systems. Unlike previous statistical translation systems, which consisted of many small sub-components that were tuned separately, NMT attempts to build and train a single, large neural network which will then be able to read a source sentence and output a translation for it. In this webinar, we will explain the use of widely available programming libraries to create a customised translation engine or model using NMT. The webinar will consist of a step-by-step demonstration of the different stages of training a NMT model, with simple explanations of the terms that are used by researchers that train these systems. The webinar will include introductory answers to questions like: What is a neural network? What are word embeddings? What does training and learning mean? How many stages are there in an NMT training process? What methods are there to improve the quality of the MT output? Why is the translation stage called decoding? There will be time for the participants to ask questions, but they are not expected to perform any hands-on work. As a follow-up to the webinar, we are preparing a short course with hands-on exercises for participants to train their own initial models. ","tags":["talks","machine translation","neural machine translation","translators"],"title":"Introducing Neural Machine Translation (NMT) to Translators","type":"talk"},{"authors":["Prashant Sharma","Hadeel Saadany","Leonardo Zilio","Diptesh Kanojia","Constantin Orăsan"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"f8b1ca39c8e96022252d11cf0a7fc0f2","permalink":"https://dipteshkanojia.co.uk/publication/sdu-st-aaai-2022-acronym/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/publication/sdu-st-aaai-2022-acronym/","section":"publication","summary":"Acronyms are abbreviated units of a phrase constructed by using initial components of the phrase in a text. Automatic extraction of acronyms from a text can help various Natural Language Processing tasks like machine translation, information retrieval, and text summarisation. This paper discusses an ensemble approach for the task of Acronym Extraction, which utilises two different methods to extract acronyms and their corresponding long forms. The first method utilises a multilingual contextual language model and fine-tunes the model to perform the task. The second method relies on a convolutional neural network architecture to extract acronyms and append them to the output of the previous method. We also augment the official training dataset with additional training samples extracted from several open-access journals to help improve the task performance. Our dataset analysis also highlights the noise within the current task dataset. Our approach achieves the following macro-F1 scores on test data released with the task: Danish (0.74), English-Legal (0.72), English-Scientific (0.73), French (0.63), Persian (0.57), Spanish (0.65), Vietnamese (0.65). We release our code and models publicly.","tags":["acronym extraction","shared task","data analysis","data augmentation","ensemble approach"],"title":"An Ensemble Approach to Acronym Extraction using Transformers","type":"publication"},{"authors":["Diptesh Kanojia"],"categories":null,"content":"","date":1639872000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639872000,"objectID":"b387e7b7a613898df0114abd0426a332","permalink":"https://dipteshkanojia.co.uk/talk/msrintalk/","publishdate":"2021-12-19T00:00:00Z","relpermalink":"/talk/msrintalk/","section":"talk","summary":"Current Machine Translation (MT) systems achieve very good results on a growing variety of language pairs and datasets. However, they are known to produce fluent translation outputs that can contain important meaning errors, thus undermining their reliability in practice. Quality Estimation (QE) is the task of automatically assessing the performance of MT systems at test time. Thus, in order to be useful, QE systems should be able to detect such errors. However, this ability is yet to be tested in the current evaluation practices, where QE systems are assessed only in terms of their correlation with human judgements. In this talk, we will discuss how we attempted to bridge this gap by proposing a general methodology for the adversarial testing of QE for MT. In this discussion, we first see that despite a high correlation with human judgements achieved by the recent SOTA, certain types of meaning errors are still problematic for QE to detect. We also discuss how the ability of a given model to discriminate between meaning-preserving and meaning-altering perturbations is predictive of its overall performance, thus potentially allowing us to compare the QE systems without relying on manual quality annotation. We also see possible future applications of this work and discuss various directions we are investigating to improve the performance of QE systems.","tags":["talks","quality estimation","machine translation","adversarial evaluation","probing systems"],"title":"Quality Estimation for Machine Translation","type":"talk"},{"authors":["Mrinal Rawat","Diptesh Kanojia"],"categories":null,"content":"","date":1639094400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639094400,"objectID":"bceef8e3fe8d292a43c6d0efd02bbe01","permalink":"https://dipteshkanojia.co.uk/publication/icon-2021-fakenews-evidence/","publishdate":"2021-12-10T00:00:00Z","relpermalink":"/publication/icon-2021-fakenews-evidence/","section":"publication","summary":"Fake news, misinformation, and unverifiable facts on social media platforms propagate disharmony and affect society, especially when dealing with an epidemic like COVID-19. The task of Fake News Detection aims to tackle the effects of such misinformation by classifying news items as fake or real. In this paper, we propose a novel approach that improves over the current automatic fake news detection approaches by automatically gathering evidence for each claim. Our approach extracts supporting evidence from the web articles and then selects appropriate text to be treated as evidence sets. We use a pre-trained summarizer on these evidence sets and then use the extracted summary as supporting evidence to aid the classification task. Our experiments, using both machine learning and deep learning-based methods, help perform an extensive evaluation of our approach. The results show that our approach outperforms the state-of-the-art methods in fake news detection to achieve an F1-score of 99.25 over the dataset provided for the CONSTRAINT-2021 Shared Task. We also release the augmented dataset, our code and models for any further research.","tags":["fake news","fake news detection","evidence collection","evidence summarization"],"title":"Automated Evidence Collection for Fake News Detection","type":"publication"},{"authors":["Diptesh Kanojia","Marina Fomicheva","Tharindu Ranasinghe","Frédéric Blain","Constantin Orăsan","Lucia Specia"],"categories":null,"content":"","date":1632528000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632528000,"objectID":"65a770bb3ef86536de758ef961998215","permalink":"https://dipteshkanojia.co.uk/publication/wmt-2021-qeeval/","publishdate":"2021-09-25T00:00:00Z","relpermalink":"/publication/wmt-2021-qeeval/","section":"publication","summary":"Current Machine Translation (MT) systems achieve very good results on a growing variety of language pairs and datasets. However, they are known to produce fluent translation outputs that can contain important meaning errors, thus undermining their reliability in practice. Quality Estimation (QE) is the task of automatically assessing the performance of MT systems at test time. Thus, in order to be useful, QE systems should be able to detect such errors. However, this ability is yet to be tested in the current evaluation practices, where QE systems are assessed only in terms of their correlation with human judgements. In this work, we bridge this gap by proposing a general methodology for adversarial testing of QE for MT. First, we show that despite a high correlation with human judgements achieved by the recent SOTA, certain types of meaning errors are still problematic for QE to detect. Second, we show that on average, the ability of a given model to discriminate between meaning-preserving and meaning-altering perturbations is predictive of its overall performance, thus potentially allowing for comparing QE systems without relying on manual quality annotation. This paper is also available on [ACL Anthology](https://aclanthology.org/2021.wmt-1.67/).","tags":["quality estimation","evaluation","machine translation","perturbations","empirical"],"title":"Pushing the Right Buttons: Adversarial Evaluation of Quality Estimation","type":"publication"},{"authors":["Anirudh Mittal","Pranav Jeevan","Prerak Gandhi","Diptesh Kanojia","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1632441600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632441600,"objectID":"e0ec231d417796a9a90451e4093e8b45","permalink":"https://dipteshkanojia.co.uk/publication/emnlp-2021-standup/","publishdate":"2021-09-24T00:00:00Z","relpermalink":"/publication/emnlp-2021-standup/","section":"publication","summary":"Computational Humour (CH) has attracted the interest of Natural Language Processing and Computational Linguistics communities. Creating datasets for automatic measurement of humour quotient is difficult due to multiple possible interpretations of the content. In this work, we create a multi-modal humour-annotated dataset (~40 hours) using stand-up comedy clips. We devise a novel scoring mechanism to annotate the training data with a humour quotient score using the audience's laughter. The normalized duration (laughter duration divided by the clip duration) of laughter in each clip is used to compute this humour coefficient score on a five-point scale (0-4). This method of scoring is validated by comparing with manually annotated scores, wherein a quadratic weighted kappa of 0.6 is obtained. We use this dataset to train a model that provides a 'funniness' score, on a five-point scale, given the audio and its corresponding text. We compare various neural language models for the task of humour-rating and achieve an accuracy of 0.813 in terms of Quadratic Weighted Kappa (QWK). Our 'Open Mic' dataset is released for further research along with the code.","tags":["computational humour","rating humour","standup comedy","multimodal","dataset","empirical"],"title":"'So You Think You’re Funny?': Rating the Humour Quotient in Standup Comedy","type":"publication"},{"authors":["Girishkumar Ponkiya","Diptesh Kanojia","Pushpak Bhattacharyya","Girish Palshikar"],"categories":null,"content":"","date":1627776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627776000,"objectID":"a2099c867e03f4ac2f0c8f970807cae3","permalink":"https://dipteshkanojia.co.uk/publication/aclfind-2021-nci/","publishdate":"2021-08-01T00:00:00Z","relpermalink":"/publication/aclfind-2021-nci/","section":"publication","summary":"Given a noun compound (NC), we address the problem of predicting the appropriate semantic label linking the constituents of the NC. This problem is called Noun Compound Interpretation (NCI). We use FrameNet as a semantic label repository. For example, given the noun compound (board approval), we predict the frame (DENY OR GRANT PERMISSION, as per FrameNet) as appropriate and the semantic role of the modifier word (AUTHORITY) as the semantic label linking board and approval; the resulting label is DENY OR GRANT PERMISSION:AUTHORITY. Our semantic label repository is very large (≈11k labels) compared to the NC data available for training (approx 1900). Thus, learning in this case, especially for unseen semantic labels, is hard. We propose to solve this problem by predicting semantic labels in a continuous label embedding space, which is novel. This embedding space is created by learning label embeddings using the FrameNet data. The embeddings are then used to train two separate models – one for predicting Frames and the other for FEs. As the label embedding space captures the semantics of the labels, using these embeddings enables generalizing well on unseen labels, thus achieving zero-shot learning. Our preliminary investigations show that the proposed approach performs well for unseen labels, achieving 5% and 2% points improvements over baselines for the frame and FE prediction, respectively. The study shows the promise of the use of continuous space embeddings for noun compound interpretation and points to the need for further investigation.","tags":["noun-compound","deep learning","framenet","theoretical"],"title":"FrameNet-assisted Noun Compound Interpretation","type":"publication"},{"authors":["Diptesh Kanojia","Prashant Sharma","Sayali Ghodekar","Pushpak Bhattacharyya","Gholamreza Haffari","Malhar Kulkarni"],"categories":null,"content":"","date":1619136000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619136000,"objectID":"9975875309a41d4a552b44995a750bfe","permalink":"https://dipteshkanojia.co.uk/publication/eacl-2021-cognate/","publishdate":"2021-04-23T00:00:00Z","relpermalink":"/publication/eacl-2021-cognate/","section":"publication","summary":"Automatic detection of cognates helps downstream NLP tasks of Machine Translation, Cross-lingual Information Retrieval, Computational Phylogenetics and Cross-lingual Named Entity Recognition. Previous approaches for the task of cognate detection use orthographic, phonetic and semantic similarity based features sets. In this paper, we propose a novel method for enriching the feature sets, with cognitive features extracted from human readers' gaze behaviour. We collect gaze behaviour data for a small sample of cognates and show that extracted cognitive features help the task of cognate detection. However, gaze data collection and annotation is a costly task. We use the collected gaze behaviour data to predict cognitive features for a larger sample and show that predicted cognitive features, also, significantly improve the task performance. We report improvements of 10% with the collected gaze features, and 12% using the predicted gaze features, over the previously proposed approaches. Furthermore, we release the collected gaze behaviour data along with our code and cross-lingual models.  *This paper was awarded an honourable mention during the best papers award in the long papers category at EACL 2021.*  ","tags":["best paper honourable mention","gaze tracking","deep learning","cognate detection","experimental","cross lingual"],"title":"Cognition-aware Cognate Detection","type":"publication"},{"authors":["Rudra Murthy","Tamali Banerjee","Jyotsana Khatri","Diptesh Kanojia","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1608285600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608285600,"objectID":"c77a7694ddfde2103b92aaa2174c004f","permalink":"https://dipteshkanojia.co.uk/talk/icontutorial-2020/","publishdate":"2020-12-18T10:00:00Z","relpermalink":"/talk/icontutorial-2020/","section":"talk","summary":"The focus of this tutorial is to cover the breadth of the literature on recent advances in Unsupervised Machine Translation. The tutorial will help the audience in getting started with unsupervised machine translation. The tutorial will span over three sections. In the first section, we will cover the fundamental concepts like cross-lingual embeddings, denoising auto-encoders, language model pre-training, Back Translation (BT), etc. which are key to the success of Unsupervised Machine Translation. In the second section, the tutorial will provide a brief summary of recent works on unsupervised machine translation. The tutorial will cover both Phrase-Based Statistical Machine Translation systems as well as Neural Machine Translation systems. In the last section, we will talk about the limitations of the existing approaches for Unsupervised machine translation approaches and provide general guidelines for successful training of these systems. We also discuss case-studies from Indian languages and provide results obtained with U-MT over Indian language pairs. Finally, we talk about possible research directions.","tags":["machine translation","tutorial","unsupervised"],"title":"Unsupervised Neural Machine Translation","type":"talk"},{"authors":["Diptesh Kanojia","Raj Dabre","Shubham Dewangan","Pushpak Bhattacharyya","Gholamreza Haffari","Malhar Kulkarni"],"categories":null,"content":"","date":1606867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606867200,"objectID":"a1858fcf86b499ef0e30b8bad039c554","permalink":"https://dipteshkanojia.co.uk/publication/coling-2020-cognate/","publishdate":"2020-12-02T00:00:00Z","relpermalink":"/publication/coling-2020-cognate/","section":"publication","summary":"Cognates are variants of the same lexical form across different languages; for example 'fonema' in Spanish and 'phoneme' in English are cognates, both of which mean 'a unit of sound'. The task of automatic detection of cognates among any two languages can help downstream NLP tasks such as Cross-lingual Information Retrieval, Computational Phylogenetics, and Machine Translation. In this paper, we demonstrate the use of cross-lingual word embeddings for detecting cognates among fourteen Indian Languages. Our approach introduces the use of context from a knowledge graph to generate improved feature representations for cognate detection. We, then, evaluate the impact of our cognate detection mechanism on neural machine translation (NMT), as a downstream task. We evaluate our methods to detect cognates on a challenging dataset of twelve Indian languages, namely, Sanskrit, Hindi, Assamese, Oriya, Kannada, Gujarati, Tamil, Telugu, Punjabi, Bengali, Marathi, and Malayalam. Additionally, we create evaluation datasets for two more Indian languages, Konkani and Nepali. We observe an improvement of up to 18% points, in terms of F-score, for cognate detection. Furthermore, we observe that cognates extracted using our method help improve NMT quality by up to 2.76 BLEU. We also release our code, newly constructed datasets and cross-lingual models publicly.","tags":["cognate detection","machine translation","deep learning","cross-lingual","theoretical"],"title":"Harnessing Cross-lingual Features to Improve Cognate Detection for Low-resource Languages","type":"publication"},{"authors":["Sandeep Mathias","Diptesh Kanojia","Abhijit Mishra","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"e54942e6417a4d853f2e710cd64d19b6","permalink":"https://dipteshkanojia.co.uk/publication/ijcai-2020-gazesurvey/","publishdate":"2020-12-01T00:00:00Z","relpermalink":"/publication/ijcai-2020-gazesurvey/","section":"publication","summary":"Gaze behaviour has been used as a way to gather cognitive information for a number of years. In this paper, we discuss the use of gaze behaviour in solving different tasks in natural language processing (NLP) without having to record it at test time. This is because the collection of gaze behaviour is a costly task, both in terms of time and money. Hence, in this paper, we focus on research done to alleviate the need for recording gaze behaviour at run time. We also mention different eye tracking corpora in multiple languages, which are currently available and can be used in natural language processing. We conclude our paper by discussing applications in a domain - education - and how learning gaze behaviour can help in solving the tasks of complex word identification and automatic essay grading.","tags":["gaze tracking","deep learning","machine learning","survey","theoretical"],"title":"A Survey on Using Gaze Behaviour for Natural Language Processing","type":"publication"},{"authors":["Sandeep Mathias","Rudra Murthy","Diptesh Kanojia","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"6248fd9598092cf6b443b649790d8e7d","permalink":"https://dipteshkanojia.co.uk/publication/icon-2020-aeg/","publishdate":"2020-12-01T12:40:43.631013Z","relpermalink":"/publication/icon-2020-aeg/","section":"publication","summary":"Automatic essay grading (AEG) is a process in which machines assign a grade to an essay written in response to a topic, called the prompt. Zero-shot AEG is when we train a system to grade essays written to a new prompt which was not present in our training data. In this paper, we describe a solution to the problem of zero-shot automatic essay grading, using cognitive information, in the form of gaze behaviour. Our experiments show that using gaze behaviour helps in improving the performance of AEG systems, especially when we provide a new essay written in response to a new prompt for scoring, by an average of almost 5 percentage points of QWK.","tags":["gaze tracking","deep learning","automatic essay grading","experimental","zero-shot"],"title":"Cognitively Aided Zero-Shot Automatic Essay Grading","type":"publication"},{"authors":["Sandeep Mathias","Rudra Murthy","Diptesh Kanojia","Abhijit Mishra","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"7b5f4ef33d9eb67598db163c79e5f98a","permalink":"https://dipteshkanojia.co.uk/publication/aacl-2020-aeg/","publishdate":"2020-12-01T00:00:00Z","relpermalink":"/publication/aacl-2020-aeg/","section":"publication","summary":"The gaze behaviour of a reader is helpful in solving several NLP tasks such as automatic essay grading. However, collecting gaze behaviour from readers is costly in terms of time and money. In this paper, we propose a way to improve automatic essay grading using gaze behaviour, which is learnt at run time using a multi-task learning framework. To demonstrate the efficacy of this multi-task learning based approach to automatic essay grading, we collect gaze behaviour for 48 essays across 4 essay sets, and learn gaze behaviour for the rest of the essays, numbering over 7000 essays. Using the learnt gaze behaviour, we can achieve a statistically significant improvement in performance over the state-of-the-art system for the essay sets where we have gaze data. We also achieve a statistically significant improvement for 4 other essay sets, numbering about 6000 essays, where we have no gaze behaviour data available. Our approach establishes that learning gaze behaviour improves automatic essay grading.","tags":["gaze tracking","deep learning","automatic essay grading","experimental","multi-tasking"],"title":"Happy Are Those Who Grade without Seeing: A Multi-Task Learning Approach to Grade Essays Using Gaze Behaviour","type":"publication"},{"authors":["Diptesh Kanojia"],"categories":null,"content":"","date":1585888200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585888200,"objectID":"116886f40cb508a4020abd7f3c9b3c04","permalink":"https://dipteshkanojia.co.uk/talk/csirotalk/","publishdate":"2020-04-03T05:30:00+01:00","relpermalink":"/talk/csirotalk/","section":"talk","summary":"In this talk, I present my primary PhD contributions where different embeddings aid in the tasks of cognate detection, and computational phylogenetics. A set of unpublished results which show that cognates, indeed, help in the downstream task of machine translation were also shown.","tags":["talks","cognate detection","semantics","distributional semantics"],"title":"Investigations into the use of Distributed Semantics for Cognate Detection and Computational Phylogenetics","type":"talk"},{"authors":["Kumar Saurav","Kumar Saunack","Diptesh Kanojia","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"07f94860429b6410e87565e02aa8b937","permalink":"https://dipteshkanojia.co.uk/publication/lrec-2020-embeddings/","publishdate":"2020-04-01T00:00:00Z","relpermalink":"/publication/lrec-2020-embeddings/","section":"publication","summary":"Dense word vectors or 'word embeddings' which encode semantic properties of words, have now become integral to NLP tasks like Machine Translation (MT), Question Answering (QA), Word Sense Disambiguation (WSD), and Information Retrieval (IR). In this paper, we use various existing approaches to create multiple word embeddings for 14 Indian languages. We place these embeddings for all these languages, viz., Assamese, Bengali, Gujarati, Hindi, Kannada, Konkani, Malayalam, Marathi, Nepali, Odiya, Punjabi, Sanskrit, Tamil, and Telugu in a single repository. Relatively newer approaches that emphasize catering to context (BERT, ELMo, etc.) have shown significant improvements, but require a large amount of resources to generate usable models. We release pre-trained embeddings generated using both contextual and non-contextual approaches. We also use MUSE and XLM to train cross-lingual embeddings for all pairs of the aforementioned languages. To show the efficacy of our embeddings, we evaluate our embedding models on XPOS, UPOS and NER tasks for all these languages. We release a total of 436 models using 8 different approaches. We hope they are useful for the resource-constrained Indian language NLP. The title of this paper refers to the famous novel 'A Passage to India' by E.M. Forster, published initially in 1924.","tags":["word embeddings","cross-lingual word embeddings","indian language embeddings","resource","theoretical"],"title":"\"A Passage to India\": Pre-trained Word Embeddings for Indian Languages","type":"publication"},{"authors":["Diptesh Kanojia","Pushpak Bhattacharyya","Malhar Kulkarni","Gholamreza Haffari"],"categories":null,"content":"","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"307fb61de2abeeed2f98db86e2b11575","permalink":"https://dipteshkanojia.co.uk/publication/lrec-2020-cognate/","publishdate":"2020-04-01T00:00:00Z","relpermalink":"/publication/lrec-2020-cognate/","section":"publication","summary":"Cognates are present in multiple variants of the same text across different languages (e.g., hund in German and hound in English language mean dog). They pose a challenge to various Natural Language Processing (NLP) applications such as Machine Translation, Cross-lingual Sense Disambiguation, Computational Phylogenetics, and Information Retrieval. A possible solution to address this challenge is to identify cognates across language pairs. In this paper, we describe the creation of two cognate datasets for twelve Indian languages, namely Sanskrit, Hindi, Assamese, Oriya, Kannada, Gujarati, Tamil, Telugu, Punjabi, Bengali, Marathi, and Malayalam. We digitize the cognate data from an Indian language cognate dictionary and utilize linked Indian language Wordnets to generate cognate sets. Additionally, we use the Wordnet data to create a False Friends' dataset for eleven language pairs. We also evaluate the efficacy of our dataset using previously available baseline cognate detection approaches. We also perform a manual evaluation with the help of lexicographers and release the curated gold-standard dataset with this paper.","tags":["cognate detection","false friends detection","cognate dataset","false friends dataset","cross-lingual word embeddings","embeddings","resource","theoretical"],"title":"Challenge Datasets of Cognate and False Friend Pairs for Indian Languages","type":"publication"},{"authors":["Akash Sheoran","Diptesh Kanojia","Aditya Joshi","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"e58703b275c504a68aade802ea2b0b3f","permalink":"https://dipteshkanojia.co.uk/publication/lrec-2020-cdsa/","publishdate":"2020-04-01T00:00:00Z","relpermalink":"/publication/lrec-2020-cdsa/","section":"publication","summary":"Cross-domain sentiment analysis (CDSA) helps to address the problem of data scarcity in scenarios where labelled data for a domain (known as the target domain) is unavailable or insufficient. However, the decision to choose a domain (known as the source domain) to leverage from is, at best, intuitive. In this paper, we investigate text similarity metrics to facilitate source domain selection for CDSA. We report results on 20 domains (all possible pairs) using 11 similarity metrics. Specifically, we compare CDSA performance with these metrics for different domain-pairs to enable the selection of a suitable source domain, given a target domain. These metrics include two novel metrics for evaluating domain adaptability to help source domain selection of labelled data and utilize word and sentence-based embeddings as metrics for unlabelled data. The goal of our experiments is a recommendation chart that gives the K best source domains for CDSA for a given target domain. We show that the best K source domains returned by our similarity metrics have a precision of over 50%, for varying values of K.","tags":["cross-domain sentiment analysis","sentiment analysis","source domain selection","word embeddings","embeddings","theoretical"],"title":"Recommendation Chart of Domains for Cross-Domain Sentiment Analysis: Findings of A 20 Domain Study","type":"publication"},{"authors":["Diptesh Kanojia","Malhar Kulkarni","Sayali Ghodekar","Eivind Kahrs","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1582156800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582156800,"objectID":"81a9a9b67ad295b7ff4b0ae90a0ae543","permalink":"https://dipteshkanojia.co.uk/publication/sssu-2020-commentaries/","publishdate":"2020-02-20T00:00:00Z","relpermalink":"/publication/sssu-2020-commentaries/","section":"publication","summary":"This paper describes additional aspects of a digital tool called the ‘Textual History Tool’. We describe its various salient features with special reference to those of its features that may help the philologist digitize commentaries and sub-commentaries on a text. This tool captures the historical evolution of a text through various temporal stages, and interrelated data culled from various types of related texts. We use the text of the Kāśikāvṛtti (KV) as a sample text, and with the help of philologists, we digitize the commentaries available to us. We digitize the Nyāsa (Ny), the Padamañjarī (Pm) and sub commentaries on the KV text known as the Tantrapradīpa (Tp), and the Makaranda (Mk). We divide each commentary and sub-commentary into functional units and describe the methodology and motivation behind the functional unit division. Our functional unit division helps generate more accurate phylogenetic trees for the text, based on distance methods using the data entered in the tool.","tags":["commentaries","textual history","word embeddings","phylogenetics","embeddings","theoretical"],"title":"Strategies of Effective Digitization of Commentaries and Sub-commentaries: Towards the Construction of Textual History","type":"publication"},{"authors":["Diptesh Kanojia","Sravan Munukutla","Sayali Ghodekar","Pushpak Bhattacharyya","Malhar Kulkarni"],"categories":null,"content":"","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578614400,"objectID":"2bae9b13755fd7baf334ac054304a510","permalink":"https://dipteshkanojia.co.uk/publication/cods-2020-cognate/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/publication/cods-2020-cognate/","section":"publication","summary":"Automatic Cognate Detection helps NLP tasks of Machine Translation, Information Retrieval, and Phylogenetics. Cognate words are defined as word pairs across languages which exhibit partial or full lexical similarity and mean the same (e.g., hund-hound in German-English). In this paper, we use a Siamese Feed-forward neural network with word-embeddings to detect such word pairs. Our experiments with various embedding dimensions show larger embedding dimensions can only be used for large corpora sizes for this task. On a dataset built using linked Indian Wordnets, our approach beats the baseline approach with a significant margin (up to 71%) with the best F-score of 0.85% on the Hindi-Gujarati language pair.","tags":["word embeddings","cognate detection","indian languages","siamese networks","theoretical"],"title":"\"Keep Your Dimensions on a Leash\": True Cognate Detection using Siamese Deep Neural Networks","type":"publication"},{"authors":["Yashasvi Mantha","Diptesh Kanojia","Pushpak Bhattacharyya","Malhar Kulkarni"],"categories":null,"content":"","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578614400,"objectID":"d26dd4fbece12c6a51f82f1eba233ad4","permalink":"https://dipteshkanojia.co.uk/publication/cods-2020-typological/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/publication/cods-2020-typological/","section":"publication","summary":"Establishing language relatedness by inferring phylogenetic trees has been a topic of interest in the area of diachronic linguistics. However, existing methods face meaning conflation deficiency due to the usage of lexical similarity-based measures. In this paper, we utilize fourteen linked Indian Wordnets to create inter-language distances using our novel approach to compute ‘language distances’. Our pilot study uses deep cross-lingual word embeddings to compute inter-language distances and provide an effective distance matrix to infer phylogenetic trees. We also develop a baseline method using lexical similarity-based metrics for comparison and identify that our approach produces better phylogenetic trees which club related languages closer when compared to the baseline approach.","tags":["word embeddings","phylogenetics","typological trees","cross-lingual word embeddings","theoretical"],"title":"Harnessing Deep Cross-lingual Word Embeddings to Infer Accurate Phylogenetic Trees","type":"publication"},{"authors":["Diptesh Kanojia","Abhijeet Dubey","Malhar Kulkarni","Pushpak Bhattacharyya","Gholamreza Haffari"],"categories":null,"content":"","date":1571961600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571961600,"objectID":"bc534447faaf590d1c3fe196bdc48ece","permalink":"https://dipteshkanojia.co.uk/publication/iscls-2019-embeddings/","publishdate":"2019-10-25T00:00:00Z","relpermalink":"/publication/iscls-2019-embeddings/","section":"publication","summary":"Tracing the root of a text i.e., the original version of the text, by inferring phylogenetic trees has been a topic of interest in philological studies. However, existing methods face meaning conflation deficiency due to the usage of lexical similarity based measures which feed the distance matrix to clustering algorithms. In this paper, we utilize word embeddings as features to compute the distances among manuscripts. We conduct this pilot study on using word embeddings to compute inter-manuscript distances and provide an effective distance matrix to infer phylogenetic trees. We conduct experiments on the historical Sanskrit text known as Kāśikāvrtti (KV) and infer phylogenetic trees using this approach. For comparison, we also develop baseline methods using lexical distance-based measures to infer phylogenetic trees for KV. We show that our methodology produces better trees which club closely related manuscripts together compared to the baseline methods.","tags":["word embeddings","phylogenetics","embeddings","theoretical"],"title":"Utilizing Word Embeddings based Features for Phylogenetic Tree Generation of Sanskrit Texts","type":"publication"},{"authors":["Diptesh Kanojia","Malhar Kulkarni","Pushpak Bhattacharyya","Sayali Ghodekar","Irawati Kulkarni","Nilesh Joshi","Eivind Kahrs"],"categories":null,"content":"","date":1561248000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561248000,"objectID":"0a309fb6d49cf4b91cf021d008379445","permalink":"https://dipteshkanojia.co.uk/publication/iscls-2019-tht/","publishdate":"2019-06-23T00:00:00Z","relpermalink":"/publication/iscls-2019-tht/","section":"publication","summary":"This paper describes a digital tool called the Textual History Tool in detail. This tool captures the historical evolution of a text through various temporal stages, and inter-related data culled from various types of related texts. This tool also provides a historical view of the transmission of a text through the manuscript tradition. This tool provides an online interface which allows philologists to enter manuscript data for a text. It also provides an online interface which helps philologists compare the variants in a separate mode. It allows the user to generate phylogenetic trees, for the text, based on distance methods using the data entered in the tool. It also contains the facility to generate critical edition using a semi-supervised approach. This tool also divides the text into meaningful functional units and helps achieve a better comparison among the manuscripts. The text of the KV and its textual history is mentioned as a specific example to demostrate the features of this tool.","tags":["embeddings","phylogenetics","tool","online","implementation"],"title":"An Introduction to the Textual History Tool","type":"publication"},{"authors":["Diptesh Kanojia","Kevin Patel","Pushpak Bhattacharyya","Malhar Kulkarni","Gholamreza Haffari"],"categories":null,"content":"","date":1561248000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561248000,"objectID":"56e2d449f474e8143cdc46494c93a707","permalink":"https://dipteshkanojia.co.uk/publication/gwc-2019-cognate/","publishdate":"2019-06-23T00:00:00Z","relpermalink":"/publication/gwc-2019-cognate/","section":"publication","summary":"Automatic Cognate Detection (ACD) is a challenging task which has been utilized to help NLP applications like Machine Translation, Information Retrieval and Computational Phylogenetics. Unidentified cognate pairs can pose a challenge to these applications and result in a degradation of performance. In this paper, we detect cognate word pairs among ten Indian languages with Hindi and use deep learning methodologies to predict whether a word pair is cognate or not. We identify IndoWordnet as a potential resource to detect cognate word pairs based on orthographic similarity-based methods and train neural network models using the data obtained from it. We identify parallel corpora as another potential resource and perform the same experiments for them. We also validate the contribution of Wordnets through further experimentation and report improved performance of up to 26%. We discuss the nuances of cognate detection among closely related Indian languages and release the lists of detected cognates as a dataset. We also observe the behaviour of, to an extent, unrelated Indian language pairs and release the lists of detected cognates among them as well.","tags":["cognate detection","phylogenetics","wordnets","theoretical"],"title":"Utilizing Wordnets for Cognate Detection among Indian Languages","type":"publication"},{"authors":["Diptesh Kanojia","Malhar Kulkarni","Pushpak Bhattacharyya","Gholamreza Haffari"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"61c3322c291fdf21d26a7391097536ee","permalink":"https://dipteshkanojia.co.uk/publication/kanojia-2019-cognate/","publishdate":"2019-06-27T12:40:43.659033Z","relpermalink":"/publication/kanojia-2019-cognate/","section":"publication","summary":"Cognates are present in multiple variants of the same text across different languages. Computational Phylogenetics uses algorithms and techniques to analyze these variants and infer phylogenetic trees for a hypothesized accurate representation based on the output of the computational algorithm used. In our work, we detect cognates among a few Indian languages namely Hindi, Marathi, Punjabi, and Sanskrit for helping build cognate sets for phylogenetic inference. Cognate detection helps phylogenetic inference by helping isolate diachronic sound changes and thus detect the words of a common origin. A cognate set manually annotated with the help of a lexicographer is generally used to automatically infer phylogenetic trees. Our work creates cognate sets of each language pair and infers phylogenetic trees based on a bayesian framework using the Maximum likelihood method. We also implement our work to an online interface and infer phylogenetic trees based on automatically detected cognate sets. The online interface helps create phylogenetic trees based on the textual data provided as an input. It helps a lexicographer provide manual input of data, edit the data based on their expert opinion and eventually create phylogenetic trees based on various algorithms including our work on automatically creating cognate sets. We go on to discuss the nuances in detection cognates with respect to these Indian languages and also discuss the categorization of Cognate words i.e., 'Tatasama' and 'Tadbhava' words.","tags":["cognate detection","wordnets","linguistics","phylogenetics"],"title":"Cognate Identification to improve Phylogenetic trees for Indian Languages","type":"publication"},{"authors":["Swaraja Salaskar","Diptesh Kanojia","Malhar Kulkarni"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"c8545d3558190c1f5e7c488362e5cbf7","permalink":"https://dipteshkanojia.co.uk/publication/salaskar-2019-some/","publishdate":"2019-06-27T12:40:43.659403Z","relpermalink":"/publication/salaskar-2019-some/","section":"publication","summary":"In today’s digital world language technology has gained importance. Several software, have been developed and are available in the field of computational linguistics. Such tools play a crucial role in making classical language texts easily accessible. Some Indian philosophical schools have contributed towards various techniques of verbal cognition to analyze sentence correctly. These theories can be used to build computational tools for word sense disambiguation (WSD). In the absence of WSD, one cannot have proper verbal cognition. These theories considered the concept of ‘Yogyatā’ (congruity or compatibility) as the indispensable cause of verbal cognition. In this work, we come up with some insights on the basis of these theories to create a tool that will capture Yogyatā of words. We describe the problem of ambiguity in a text and present a method to resolve it computationally with the help of Yogyatā. Here, only two major schools i.e. Nyāya and Vyākaraṇa are considered. Our paper attempts to show the implication of the creation of our tool in this area. Also, our tool involves the creation of an ‘ontological tag-set’ as well as strategies to mark up the lexicon. The introductory description of ablation is also covered in this paper. Such strategies and some case studies shall form the core of our paper.","tags":["word sense disambiguation","sanskrit","linguistics"],"title":"Some Strategies to Capture Karaka-Yogyata with Special Reference to apadana","type":"publication"},{"authors":["Diptesh Kanojia"],"categories":null,"content":"","date":1544878800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544878800,"objectID":"c46e5d205d31b278be6c8ed9867f9473","permalink":"https://dipteshkanojia.co.uk/talk/techfestalk/","publishdate":"2018-12-15T13:00:00Z","relpermalink":"/talk/techfestalk/","section":"talk","summary":"In this talk, I discuss Natural Language Processing, Data Science and how they are related to each other. While presenting the different facets of the NLP research done at our lab, I connected it to how a data scientist can use the research to solve a relatable real-world issue. I discussed the NLP research areas of Machine Translation, Sentiment Analysis, Sarcasm Detection, Speech Processing, Cognitive NLP and then went into details of Computational Phylogenetics and Cognate Detection, the latter two being a part of my Ph.D. Thesis. I also presented some excerpts of his work from a recent publication at CODS-COMAD 2019 and explained how Cognate detection is an important problem in the area of Historical and Cultural Linguistics. The talk was well received as the feedback from the students and some entrepreneurs were positive. Later, it transcended more into an interactive session on what tools can an amateur use to start NLP and what online courses can one pursue to deal with these NLP problems.","tags":["talks"],"title":"Natural Language Processing and its intersection with Data Science","type":"talk"},{"authors":["Sandeep Mathias","Diptesh Kanojia","Kevin Patel","Samarth Agarwal","Abhijit Mishra","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"b0de83230d96792faac13f9cd22589dc","permalink":"https://dipteshkanojia.co.uk/publication/mathias-2018-eyes/","publishdate":"2019-06-27T12:40:43.658566Z","relpermalink":"/publication/mathias-2018-eyes/","section":"publication","summary":"Predicting a reader's rating of text quality is a challenging task that involves estimating different subjective aspects of the text, like structure, clarity, etc. Such subjective aspects are better handled using cognitive information. One such source of cognitive information is gaze behaviour. In this paper, we show that gaze behaviour does indeed help in effectively predicting the rating of text quality. To do this, we first we model text quality as a function of three properties - organization, coherence and cohesion. Then, we demonstrate how capturing gaze behaviour helps in predicting each of these properties, and hence the overall quality, by reporting improvements obtained by adding gaze features to traditional textual features for score prediction. We also hypothesize that if a reader has fully understood the text, the corresponding gaze behaviour would give a better indication of the assigned rating, as opposed to partial understanding. Our experiments validate this hypothesis by showing greater agreement between the given rating and the predicted rating when the reader has a full understanding of the text.","tags":["essay grading","gaze tracking"],"title":"Eyes are the Windows to the Soul: Predicting the Rating of Text Quality Using Gaze Behaviour","type":"publication"},{"authors":["Hanumant Redkar","Rajita Shukla","Sandhya Singh","Jaya Saraswati","Laxmi Kashyap","Diptesh Kanojia","Preethi Jyothi","Malhar Kulkarni","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"6c2143e1be7cf1a37b9ff8d925206eb7","permalink":"https://dipteshkanojia.co.uk/publication/redkar-2018-hindi/","publishdate":"2019-06-27T12:40:43.636641Z","relpermalink":"/publication/redkar-2018-hindi/","section":"publication","summary":"This paper reports the work related to making Hindi Wordnet1 available as a digital resource for language learning and teaching, and the experiences and lessons that were learnt during the process. The language data of the Hindi Wordnet has been suitably modified and enhanced to make it into a language learning aid. This aid is based on modern pedagogical axioms and is aligned to the learning objectives of the syllabi of the school education in India. To make it into a comprehensive language tool, grammatical information has also been encoded, as far as these can be marked on the lexical items. The delivery of information is multi-layered, multi-sensory and is available across multiple digital platforms. The front end has been designed to offer an eye-catching user-friendly interface which is suitable for learners starting from age six onward. Preliminary testing of the tool has been done and it has been modified as per the feedbacks that were received. Above all, the entire exercise has offered gainful insights into learning based on associative networks and how knowledge based on such networks can be made available to modern learners.","tags":["teaching","hindi","wordnets","linguistics"],"title":"Hindi Wordnet for Language Teaching: Experiences and Lessons Learnt","type":"publication"},{"authors":["Diptesh Kanojia","Kevin Patel","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"9224743bc44e4b49ccb53dfd30ef6bc7","permalink":"https://dipteshkanojia.co.uk/publication/kanojia-2018-indian/","publishdate":"2019-06-27T12:40:43.637105Z","relpermalink":"/publication/kanojia-2018-indian/","section":"publication","summary":"Wordnets are rich lexico-semantic resources. Linked wordnets are extensions of wordnets, which link similar concepts in wordnets of different languages. Such resources are extremely useful in many Natural Language Processing (NLP) applications, primarily those based on knowledge-based approaches. In such approaches, these resources are considered as gold standard/oracle. Thus, it is crucial that these resources hold correct information. Thereby, they are created by human experts. However, human experts in multiple languages are hard to come by. Thus, the community would benefit from sharing of such manually created resources. In this paper, we release mappings of 18 Indian language wordnets linked with Princeton WordNet. We believe that availability of such resources will have a direct impact on the progress in NLP for these languages.","tags":["api","wordnets","mapping"],"title":"Indian Language Wordnets and their Linkages with Princeton WordNet","type":"publication"},{"authors":["Jayashree Gajjam","Diptesh Kanojia","Malhar Kulkarni"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"c234725d46b01454d96696ff671e0c0f","permalink":"https://dipteshkanojia.co.uk/publication/gajjam-2018-new/","publishdate":"2019-06-27T12:40:43.658152Z","relpermalink":"/publication/gajjam-2018-new/","section":"publication","summary":"A sentence is an important notion in the Indian grammatical tradition. The collection of the definitions of a sentence can be found in the text ‘Vākyapadīya’ written by Bhartṛhari in fifth century C.E. The grammarian-philosopher Bhartṛhari and his authoritative work ‘Vākyapadīya’ have been a matter of study for modern scholars, at least for more than 50 years, since Ashok Aklujkar submitted his Ph.D. dissertation at Harvard University. The notions of a sentence and a word as a meaningful linguistic unit in the language have been a subject matter for the discussion in many works that followed later on. While some scholars have applied philological techniques to critically establish the text of the works of Bhartṛhari, some others have devoted themselves to exploring philosophical insights from them. Some others have studied his works from the point of view of modern linguistics, and psychology. Few others have tried to justify the views by logical discussions. In this paper, we present a fresh view to study Bhartṛhari, and his works, especially the ‘Vākyapadīya’. This view is from the field of Natural Language Processing (NLP), more specifically, what is called as Cognitive NLP. We have studied the definitions of a sentence given by Bhartṛhari at the beginning of the second chapter of ‘Vākyapadīya’. We have researched one of these definitions by conducting an experiment and following the methodology of silent-reading of Sanskrit paragraphs. We collect the Gaze-behavior data of participants and analyze it to understand the underlying comprehension procedure in the human mind and present our results. We evaluate the statistical significance of our results using T-test, and discuss the caveats of our work. We also present some general remarks on this experiment and usefulness of this method for gaining more insights in the work of Bhartṛhari.","tags":["gaze tracking","sanskrit","linguistics","cognitive"],"title":"New Vistas to study Bhartṛhari: Cognitive NLP","type":"publication"},{"authors":["Ritesh Panjwani","Diptesh Kanojia","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"4a96343e39d82e05e1e94b8c95451501","permalink":"https://dipteshkanojia.co.uk/publication/panjwani-2018-pyiwn/","publishdate":"2019-06-27T12:40:43.636412Z","relpermalink":"/publication/panjwani-2018-pyiwn/","section":"publication","summary":"Indian language WordNets have their individual web-based browsing interfaces along with a common interface for IndoWordNet. These interfaces prove to be useful for language learners and in an educational domain, however, they do not provide the functionality of connecting to them and browsing their data through a lucid application programming interface or an API. In this paper, we present our work on creating such an easy-to-use framework which is bundled with the data for Indian language WordNets and provides NLTK WordNet interface like core functionalities in Python. Additionally, we use a pre-built speech synthesis system for Hindi language and augment Hindi data with audios for words, glosses, and example sentences. We provide a detailed usage of our API and explain the functions for ease of the user. Also, we package the IndoWordNet data along with the source code and provide it openly for the purpose of research. We aim to provide all our work as an open source framework for further development.","tags":["api","wordnets","application"],"title":"pyiwn: A Python-based API to access Indian Language WordNets","type":"publication"},{"authors":["Kevin Patel","Diptesh Kanojia","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"e549b5253c882cd4600363d7eed5ab7a","permalink":"https://dipteshkanojia.co.uk/publication/patel-2018-semi/","publishdate":"2019-06-27T12:40:43.636185Z","relpermalink":"/publication/patel-2018-semi/","section":"publication","summary":"Wordnets are rich lexico-semantic resources. Linked wordnets are extensions of wordnets, which link similar concepts in wordnets of different languages. Such resources are extremely useful in many Natural Language Processing (NLP) applications, primarily those based on knowledge-based approaches. In such approaches, these resources are considered as gold standard/oracle. Thus, it is crucial that these resources hold correct information. Thereby, they are created by human experts. However, manual maintenance of such resources is a tedious and costly affair. Thus techniques that can aid the experts are desirable. In this paper, we propose an approach to link wordnets. Given a synset of the source language, the approach returns a ranked list of potential candidate synsets in the target language from which the human expert can choose the correct one(s). Our technique is able to retrieve a winner synset in the top 10 ranked list for 60% of all synsets and 70% of noun synsets.","tags":["mapping","wordnets","linguistics"],"title":"Semi-automatic WordNet Linking using Word Embeddings","type":"publication"},{"authors":["Diptesh Kanojia","Preethi Jyothi","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"956d431caad5bf8b1c040719082e4143","permalink":"https://dipteshkanojia.co.uk/publication/kanojia-2018-synthesizing/","publishdate":"2019-06-27T12:40:43.635953Z","relpermalink":"/publication/kanojia-2018-synthesizing/","section":"publication","summary":"In this paper, we describe our work on the creation of a voice model using a speech synthesis system for the Hindi Language. We use pre-existing 'voices', use publicly available speech corpora to create a 'voice' using the Festival Speech Synthesis System (Black, 1997). Our contribution is two-fold: (1) We scrutinize multiple speech synthesis systems and provide an extensive report on the currently available state-of-the-art systems. We also develop voices using the existing implementations of the aforementioned systems, and (2) We use these voices to generate sample audios for randomly chosen words; manually evaluate the audio generated, and produce audio for all WordNet words using the winner voice model. We also produce audios for the Hindi WordNet Glosses and Example sentences. We describe our efforts to use pre-existing implementations for WaveNet - a model to generate raw audio using neural nets (Oord et al., 2016) and generate speech for Hindi. Our lexicographers perform a manual evaluation of the audio generated using multiple voices. A qualitative and quantitative analysis reveals that the voice model generated by us performs the best with an accuracy of 0.44.","tags":["speech synthesis","wordnets","linguistics","application"],"title":"Synthesizing Audio for Hindi Wordnet","type":"publication"},{"authors":["Diptesh Kanojia","Nikhil Wani","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"1d266404a0de73edef83e42e47f05123","permalink":"https://dipteshkanojia.co.uk/publication/kanojia-2017-your/","publishdate":"2019-06-27T12:40:43.636877Z","relpermalink":"/publication/kanojia-2017-your/","section":"publication","summary":"We present a quantitative, data-driven machine learning approach to mitigate the problem of unpredictability of Computer Science Graduate School Admissions. In this paper, we discuss the possibility of a system which may help prospective applicants evaluate their Statement of Purpose (SOP) based on our system output. We, then, identify feature sets which can be used to train a predictive model. We train a model over fifty manually verified SOPs for which it uses an SVM classifier and achieves the highest accuracy of 92% with 10-fold cross validation. We also perform experiments to establish that Word Embedding based features and Document Similarity based features outperform other identified feature combinations. We plan to deploy our application as a web service and release it as a FOSS service","tags":["application","sop","prediction"],"title":"Is your Statement Purposeless? Predicting Computer Science Graduation Admission Acceptance based on Statement Of Purpose","type":"publication"},{"authors":["Aditya Joshi","Diptesh Kanojia","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"84a032536fc3c0c35ab1a828c11cb8ef","permalink":"https://dipteshkanojia.co.uk/publication/joshi-2017-sarcasm/","publishdate":"2019-06-27T12:40:43.635477Z","relpermalink":"/publication/joshi-2017-sarcasm/","section":"publication","summary":"Sarcasm Suite is a browser-based engine that deploys ﬁve of our past papers in sarcasm detection and generation. The sarcasm detection modules use four kinds of incongruity: sentiment incongruity, semantic incongruity, historical context incongruity and conversational context incongruity. The sarcasm generation module is a chatbot that responds sarcastically to user input. With a visually appealing interface that indicates predictions using ‘faces’ of our co-authors from our past papers, Sarcasm Suite is our ﬁrst demonstration of our work in computational sarcasm.","tags":["sarcasm detection","application","linguistics"],"title":"Sarcasm Suite: A browser-based engine for sarcasm detection and generation","type":"publication"},{"authors":["Abhijit Mishra","Diptesh Kanojia","Seema Nagar","Kuntal Dey","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"b348baa075331214499696a99528fcf3","permalink":"https://dipteshkanojia.co.uk/publication/mishra-2017-scanpath/","publishdate":"2019-06-27T12:40:43.635707Z","relpermalink":"/publication/mishra-2017-scanpath/","section":"publication","summary":"Measuring reading effort is useful for practical purposes such as designing learning material and personalizing text comprehension environment. We propose a quantification of reading effort by measuring the complexity of eye-movement patterns of readers. We call the measure Scanpath Complexity. Scanpath complexity is modeled as a function of various properties of gaze fixations and saccades- the basic parameters of eye movement behavior. We demonstrate the effectiveness of our scanpath complexity measure by showing that its correlation with different measures of lexical and syntactic complexity as well as standard readability metrics is better than popular baseline measures based on fixation alone.","tags":["gaze tracking","theoretical"],"title":"Scanpath Complexity: Modeling Reading Effort using Gaze Information","type":"publication"},{"authors":["Diptesh Kanojia"],"categories":null,"content":"","date":1466409600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1466409600,"objectID":"84d17c1c55af735d59da07b46f39b679","permalink":"https://dipteshkanojia.co.uk/talk/vivatalk/","publishdate":"2016-06-20T09:00:00+01:00","relpermalink":"/talk/vivatalk/","section":"talk","summary":"In three different talks, I discussed various facets of fundamental NLP research being done at CFILT, IIT Bombay. The first talk one was about 'Lexical Resources' and their need in NLP tasks. During the second talk, I discussed the basics of POS tagging, Viterbi and fundamentals of NLP layers. The third talk was more of a demo session where I conducted an interactive hands-on session using Python and NLTK to demonstrate the basics.","tags":[],"title":"NLP Fundamentals at VIVA IET","type":"talk"},{"authors":null,"categories":null,"content":"One of my first few projects in Android development. I created and hosted a webview based Android application.\n","date":1461711600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461711600,"objectID":"6997b6545d3d8c63fbd89798a80f1f4f","permalink":"https://dipteshkanojia.co.uk/project/brahminet/","publishdate":"2016-04-27T00:00:00+01:00","relpermalink":"/project/brahminet/","section":"project","summary":"A webview based app for BrahmiNet.","tags":["android"],"title":"BrahmiNet - Android","type":"project"},{"authors":null,"categories":null,"content":"One of my first few projects in Android development. I created and hosted a webview based Android application.\n","date":1461711600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461711600,"objectID":"57eb5cf8a3d0474d5a7df35b12ffc540","permalink":"https://dipteshkanojia.co.uk/project/hindiwordnet/","publishdate":"2016-04-27T00:00:00+01:00","relpermalink":"/project/hindiwordnet/","section":"project","summary":"A webview based app for Hindi Wordnet.","tags":["android"],"title":"Hindi Wordnet - Android","type":"project"},{"authors":null,"categories":null,"content":"","date":1461711600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461711600,"objectID":"ae2088b800f7c0cca01611b1a57885e6","permalink":"https://dipteshkanojia.co.uk/project/hwnchromex/","publishdate":"2016-04-27T00:00:00+01:00","relpermalink":"/project/hwnchromex/","section":"project","summary":"Browser Extension for Google Chrome","tags":["extension"],"title":"HWN Chrome Browser Extension","type":"project"},{"authors":null,"categories":null,"content":"One of my first few projects in Android development. I created and hosted a webview based Android application.\n","date":1461711600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461711600,"objectID":"30c6baeab52eaf3e6a0dfe9218e04f1c","permalink":"https://dipteshkanojia.co.uk/project/marathiwordnet/","publishdate":"2016-04-27T00:00:00+01:00","relpermalink":"/project/marathiwordnet/","section":"project","summary":"A webview based app for Hindi Wordnet.","tags":["android"],"title":"Marathi Wordnet - Android","type":"project"},{"authors":null,"categories":null,"content":"","date":1461711600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461711600,"objectID":"4593405f22c9d5ca7ae6b27bb12def6e","permalink":"https://dipteshkanojia.co.uk/project/mwnchromex/","publishdate":"2016-04-27T00:00:00+01:00","relpermalink":"/project/mwnchromex/","section":"project","summary":"Browser Extension for Google Chrome","tags":["extension"],"title":"MWN Chrome Browser Extension","type":"project"},{"authors":null,"categories":null,"content":"One of my first few projects in Android development. I created and hosted a webview based Android application.\n","date":1461711600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461711600,"objectID":"c95fdefec7d6521563a933fd0837f5d1","permalink":"https://dipteshkanojia.co.uk/project/sanskritwordnet/","publishdate":"2016-04-27T00:00:00+01:00","relpermalink":"/project/sanskritwordnet/","section":"project","summary":"A webview based app for Hindi Wordnet.","tags":["android"],"title":"Sanskrit Wordnet - Android","type":"project"},{"authors":null,"categories":null,"content":"","date":1461711600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461711600,"objectID":"a076694eafe98efb8d2238d3a32e545a","permalink":"https://dipteshkanojia.co.uk/project/swnchromex/","publishdate":"2016-04-27T00:00:00+01:00","relpermalink":"/project/swnchromex/","section":"project","summary":"Browser Extension for Google Chrome","tags":["extension"],"title":"SWN Chrome Browser Extension","type":"project"},{"authors":["Diptesh Kanojia","Shehzaad Dhuliawala","Pushpak Bhattarcharyya"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"007bd1b41fccf006ff9b3e1b795aafa9","permalink":"https://dipteshkanojia.co.uk/publication/kanojia-2016-picture/","publishdate":"2019-06-27T12:40:43.633369Z","relpermalink":"/publication/kanojia-2016-picture/","section":"publication","summary":"WordNet has proved to be immensely useful for Word Sense Disambiguation, and thence Machine translation, Information Retrieval and Question Answering. It can also be used as a dictionary for educational purposes. The semantic nature of concepts in a WordNet motivates one to try to express this meaning in a more visual way. In this paper, we describe our work of enriching IndoWordNet with image acquisitions from the OpenClipArt library. We describe an approach used to enrich WordNets for eighteen Indian languages. Our contribution is three fold: (1) We develop a system, which, given a synset in English, finds an appropriate image for the synset. The system uses the OpenclipArt library (OCAL) to retrieve images and ranks them. (2) After retrieving the images, we map the results along with the linkages between Princeton WordNet and Hindi WordNet, to link several synsets to corresponding images. We choose and sort top three images based on our ranking heuristic per synset. (3) We develop a tool that allows a lexicographer to manually evaluate these images. The top images are shown to a lexicographer by the evaluation tool for the task of choosing the best image representation. The lexicographer also selects the number of relevant images. Using our system, we obtain an Average Precision (P @ 3) score of 0.30.","tags":["images","wordnets","mapping","application"],"title":"A picture is worth a thousand words: Using OpenClipArt library for enriching IndoWordNet","type":"publication"},{"authors":["Diptesh Kanojia","Vishwajeet Kumar","Krithi Ramamritham"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"f4d2b17c0c321e9b803e773952062fcb","permalink":"https://dipteshkanojia.co.uk/publication/kanojia-2016-civique/","publishdate":"2019-06-27T12:40:43.635248Z","relpermalink":"/publication/kanojia-2016-civique/","section":"publication","summary":"We present the Civique system for emergency detection in urban areas by monitoring micro blogs like Tweets. The system detects emergency related events, and classifies them into appropriate categories like 'fire', 'accident', 'earthquake', etc. We demonstrate our ideas by classifying Twitter posts in real time, visualizing the ongoing event on a map interface and alerting users with options to contact relevant authorities, both online and offline. We evaluate our classifiers for both the steps, i.e., emergency detection and categorization, and obtain F-scores exceeding 70% and 90%, respectively. We demonstrate Civique using a web interface and on an Android application, in realtime, and show its use for both tweet detection and visualization.","tags":["social media","emergency detection","application"],"title":"Civique: Using Social Media to detect Urban Emergencies","type":"publication"},{"authors":["Abhijit Mishra","Diptesh Kanojia","Seema Nagar","Kuntal Dey","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"6baf9e15971aa9affc5e05ded84ab3c0","permalink":"https://dipteshkanojia.co.uk/publication/mishra-2016-harnessing/","publishdate":"2019-06-27T12:40:43.634769Z","relpermalink":"/publication/mishra-2016-harnessing/","section":"publication","summary":"In this paper, we propose a novel mechanism for enriching the feature vector, for the task of sarcasm detection, with cognitive features extracted from eye-movement patterns of human readers. Sarcasm detection has been a challenging research problem, and its importance for NLP applications such as review summarization, dialog systems and sentiment analysis is well recognized. Sarcasm can often be traced to incongruity that becomes apparent as the full sentence unfolds. This presence of incongruity- implicit or explicit- affects the way readers eyes move through the text. We observe the difference in the behaviour of the eye, while reading sarcastic and non sarcastic sentences. Motivated by this observation, we augment traditional linguistic and stylistic features for sarcasm detection with the cognitive features obtained from readers eye movement data. We perform statistical classification using the enhanced feature set so obtained. The augmented cognitive features improve sarcasm detection by 3.7% (in terms of F-score), over the performance of the best reported system","tags":["sarcasm detection","gaze tracking","empirical"],"title":"Harnessing Cognitive Features for Sarcasm Detection","type":"publication"},{"authors":["Abhijit Mishra","Diptesh Kanojia","Seema Nagar","Kuntal Dey","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"3558e0b7f7eed704ca1626519923f10b","permalink":"https://dipteshkanojia.co.uk/publication/mishra-2016-leveraging/","publishdate":"2019-06-27T12:40:43.635012Z","relpermalink":"/publication/mishra-2016-leveraging/","section":"publication","summary":"Sentiments expressed in user-generated short text and sentences are nuanced by subtleties at lexical, syntactic, semantic and pragmatic levels. To address this, we propose to augment traditional features used for sentiment analysis and sarcasm detection, with cognitive features derived from the eye-movement patterns of readers. Statistical classification using our enhanced feature set improves the performance (F-score) of polarity detection by a maximum of 3.7% and 9.3% on two datasets, over the systems that use only traditional features. We perform feature significance analysis, and experiment on a held-out dataset, showing that cognitive features indeed empower sentiment analyzers to handle complex constructs","tags":["sentiment analysis","gaze tracking"],"title":"Leveraging Cognitive Features for Sentiment Analysis","type":"publication"},{"authors":["Meghna Singh","Rajita Shukla","Jaya Jha","Laxmi Kashyap","Diptesh Kanojia","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"2712c8503089fc117cb14c2987c656b5","permalink":"https://dipteshkanojia.co.uk/publication/singh-2016-mapping/","publishdate":"2019-06-27T12:40:43.633831Z","relpermalink":"/publication/singh-2016-mapping/","section":"publication","summary":"This paper reports the work of creating bilingual mappings in English for certain synsets of Hindi wordnet, the need for doing this, the methods adopted and the tools created for the task. Hindi wordnet, which forms the foundation for other Indian language wordnets, has been linked to the English WordNet. To maximize linkages, an important strategy of using direct and hypernymy linkages has been followed. However, the hypernymy linkages were found to be inadequate in certain cases and posed a challenge due to sense granularity of language. Thus, the idea of creating bilingual mappings was adopted as a solution. A bilingual mapping means a linkage between a concept in two different languages, with the help of translation and/or transliteration. Such mappings retain meaningful representations, while capturing semantic similarity at the same time. This has also proven to be a great enhancement of Hindi wordnet and can be a crucial resource for multilingual applications in natural language processing, including machine translation and cross language information retrieval.","tags":["bilingual","mapping","wordnets","linguistics"],"title":"Mapping it differently: A solution to the linking challenges","type":"publication"},{"authors":["Abhijit Mishra","Diptesh Kanojia","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"73d9745ec7166ccb72abc4147eb724e3","permalink":"https://dipteshkanojia.co.uk/publication/mishra-2016-predicting/","publishdate":"2019-06-27T12:40:43.634067Z","relpermalink":"/publication/mishra-2016-predicting/","section":"publication","summary":"Sarcasm understandability or the ability to understand textual sarcasm depends upon readers’ language proficiency, social knowledge, mental state and attentiveness. We introduce a novel method to predict the sarcasm understandability of a reader. Presence of incongruity in textual sarcasm often elicits distinctive eye-movement behavior by human readers. By recording and analyzing the eye-gaze data, we show that eye-movement patterns vary when sarcasm is understood vis-à-vis when it is not. Motivated by our observations, we propose a system for sarcasm understandability prediction using supervised machine learning. Our system relies on readers’ eye-movement parameters and a few textual features, thence, is able to predict sarcasm understandability with an F-score of 93%, which demonstrates its efficacy. The availability of inexpensive embedded-eye-trackers on mobile devices creates avenues for applying such research which benefits web-content creators, review writers and social media analysts alike.","tags":["sarcasm detection","understandability","gaze tracking","sentiment analysis"],"title":"Predicting Readers' Sarcasm Understandability by Modeling Gaze Behavior","type":"publication"},{"authors":["Shehzaad Dhuliawala","Diptesh Kanojia","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"980d4342984c1727c712290357a16e2f","permalink":"https://dipteshkanojia.co.uk/publication/dhuliawala-2016-slangnet/","publishdate":"2019-06-27T12:40:43.634303Z","relpermalink":"/publication/dhuliawala-2016-slangnet/","section":"publication","summary":"We present a WordNet like structured resource for slang words and neologisms on the internet. The dynamism of language is often an indication that current language technology tools trained on today's data, may not be able to process the language in the future. Our resource could be (1) used to augment the WordNet, (2) used in several Natural Language Processing (NLP) applications which make use of noisy data on the internet like Information Retrieval and Web Mining. Such a resource can also be used to distinguish slang word senses from conventional word senses. To stimulate similar innovations widely in the NLP community, we test the efficacy of our resource for detecting slang using standard bag of words Word Sense Disambiguation (WSD) algorithms (Lesk and Extended Lesk) for English data on the internet.","tags":["slang","wordnets","word sense disambiguation","theoretical"],"title":"SlangNet: A WordNet like resource for English Slang","type":"publication"},{"authors":["Diptesh Kanojia","Raj Dabre","Pushpak Bhattarcharyya"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"ee20b0bc8136ae310c91029a752bc0f4","permalink":"https://dipteshkanojia.co.uk/publication/kanojia-2016-sophisticated/","publishdate":"2019-06-27T12:40:43.633603Z","relpermalink":"/publication/kanojia-2016-sophisticated/","section":"publication","summary":"India is a country with 22 officially recognized languages and 17 of these have WordNets, a crucial resource. Web browser based interfaces are available for these WordNets, but are not suited for mobile devices which deters people from effectively using this resource. We present our initial work on developing mobile applications and browser extensions to access WordNets for Indian Languages. Our contribution is two fold: (1) We develop mobile applications for the Android, iOS and Windows Phone OS platforms for Hindi, Marathi and Sanskrit WordNets which allow users to search for words and obtain more information along with their translations in English and other Indian languages. (2) We also develop browser extensions for English, Hindi, Marathi, and Sanskrit WordNets, for both Mozilla Firefox, and Google Chrome. We believe that such applications can be quite helpful in a classroom scenario, where students would be able to access the WordNets as dictionaries as well as lexical knowledge bases. This can help in overcoming the language barrier along with furthering language understanding.","tags":["application","wordnets","linguistics"],"title":"Sophisticated Lexical Databases - Simplified Usage: Mobile Applications and Browser Plugins For Wordnets","type":"publication"},{"authors":["Diptesh Kanojia","Aaditya Joshi","Pushpak Bhattacharyya","Mark J. Carman"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"831f4ce63e9dc687d409cbee4f75f9e4","permalink":"https://dipteshkanojia.co.uk/publication/kanojia-2016-ll/","publishdate":"2019-06-27T12:40:43.63453Z","relpermalink":"/publication/kanojia-2016-ll/","section":"publication","summary":"Parallel corpora are often injected with bilingual lexical resources for improved Indian language machine translation (MT). In absence of such lexical resources, multilingual topic models have been used to create coarse lexical resources in the past, using a Cartesian product approach. Our results show that for morphologically rich languages like Hindi, the Cartesian product approach is detrimental for MT. We then present a novel 'sentential' approach to use this coarse lexical resource from a multilingual topic model. Our coarse lexical resource when injected with a parallel corpus outperforms a system trained using parallel corpus and a good quality lexical resource. As demonstrated by the quality of our coarse lexical resource and its benefit to MT, we believe that our sentential approach to create such a resource will help MT for resource-constrained languages.","tags":["topic models","machine translation","application"],"title":"That’ll do fine!: A coarse lexical resource for English-Hindi MT, using polylingual topic models","type":"publication"},{"authors":["Diptesh Kanojia","Shehzaad Dhuliawala","Naman Gupta","Abhijit Mishra","Pushpak Bhattarcharyya"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"ac46b0af2c34eb3074ad66030d8ff02a","permalink":"https://dipteshkanojia.co.uk/publication/kanojia-2015-transchat/","publishdate":"2019-06-27T12:40:43.633143Z","relpermalink":"/publication/kanojia-2015-transchat/","section":"publication","summary":"We present TransChat, an open-source, cross platform, Indian language Instant Messaging (IM) application that facilitates cross lingual textual communication over English and multiple Indian Languages. The application is a client-server IM architecture based chat system with multiple Statistical Machine Translation (SMT) engines working towards efficient translation and transmission of messages. TransChat allows users to select their preferred language and internally, selects appropriate translation engine based on the input configuration. For translation quality enhancement, necessary pre- and post-processing steps are applied on the input and output chat texts. We demonstrate the efficacy of TransChat through a series of qualitative evaluations that test- (a) The usability of the system (b) The quality of the translation output. In a multilingual country like India, such applications can help overcome language barrier in domains like tourism, agriculture and health.","tags":["machine translation","chat","application"],"title":"TransChat: Cross-Lingual Instant Messaging for Indian Languages","type":"publication"},{"authors":["Diptesh Kanojia","Aaditya Joshi","Pushpak Bhattarcharyya","Mark J. Carman"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"2b9f28d206c6f9573b1e1e46062646d5","permalink":"https://dipteshkanojia.co.uk/publication/kanojia-2015-using/","publishdate":"2019-06-27T12:40:43.632923Z","relpermalink":"/publication/kanojia-2015-using/","section":"publication","summary":"Parallel corpora are often injected with bilingual dictionaries for improved Indian language machine translation (MT). In absence of such dictionaries, a coarse dictionary may be required. This paper demonstrates the use of a multilingual topic model for creating coarse dictionaries for English-Hindi MT. We compare our approaches with: (a) a baseline with no additional dictionary injection, and (b) a corpus with a good quality dictionary. Our results show that the existing Cartesian product approach which is used to create the pseudo-parallel data results in a degradation on tourism and health datasets, for English-Hindi MT. Our paper points to the fact that existing Cartesian approach using multilingual topics (devised for European languages) may be detrimental for Indian language MT. On the other hand, we present an alternate ‘sentential’ approach that leads to a slight improvement. However, our sentential approach (using a parallel corpus injected with a coarse dictionary) outperforms a system trained using parallel corpus and a good quality dictionary.","tags":["topic models","machine translation","application"],"title":"Using Multilingual Topic Models for Improved Alignment in English-Hindi MT","type":"publication"},{"authors":["Hanumant Harichandra Redkar","Sudha Baban Bhingardive","Diptesh Kanojia","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"bd887cc7ad0ca678dfd99c5c00ddf912","permalink":"https://dipteshkanojia.co.uk/publication/redkar-2015-world/","publishdate":"2019-06-27T12:40:43.632029Z","relpermalink":"/publication/redkar-2015-world/","section":"publication","summary":"WordNet is an online lexical resource which expresses unique concepts in a language. English WordNet is the first WordNet which was developed at Princeton University. Over a period of time, many language WordNets were developed by various organizations all over the world. It has always been a challenge to store the WordNet data. Some WordNets are stored using file system and some WordNets are stored using different database models. In this paper, we present the World WordNet Database Structure which can be used to efficiently store the WordNet information of all languages of the World. This design can be adapted by most language WordNets to store information such as synset data, semantic and lexical relations, ontology details, language specific features, linguistic information, etc. An attempt is made to develop Application Programming Interfaces to manipulate the data from these databases. This database structure can help in various Natural Language Processing applications like Multilingual Information Retrieval, Word Sense Disambiguation, Machine Translation, etc.","tags":["wordnets","demo","application"],"title":"World WordNet database structure: an efficient schema for storing information of WordNets of the world","type":"publication"},{"authors":["Diptesh Kanojia","Pushpak Bhattacharyya","Raj Dabre","Siddhartha Gunti","Manish Shrivastava"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"8fb4d28ee4dfcc35196262f68fd2225a","permalink":"https://dipteshkanojia.co.uk/publication/kanojia-2014-not/","publishdate":"2019-06-27T12:40:43.631806Z","relpermalink":"/publication/kanojia-2014-not/","section":"publication","summary":"The task of Word Sense Disambiguation (WSD) incorporates in its definition the role of ‘context’. We present our work on the development of a tool which allows for automatic acquisition and ranking of ‘context clues’ for WSD. These clue words are extracted from the contexts of words appearing in a large monolingual corpus. These mined collection of contextual clues form a discrimination net in the sense that for targeted WSD, navigation of the net leads to the correct sense of a word given its context. Utilizing this resource we intend to develop efficient and light weight WSD based on look up and navigation of memory-resident knowledge base, thereby avoiding heavy computation which often prevents incorporation of any serious WSD in MT and search. The need for large quantities of sense marked data too can be reduced.","tags":["wordnets","word sense disambiguation","theoretical"],"title":"Do not do processing, when you can look up: Towards a Discrimination Net for WSD","type":"publication"},{"authors":["Diptesh Kanojia","Manish Shrivastava","Raj Dabre","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"a5bb7954e38e4049139a6644ccfab71d","permalink":"https://dipteshkanojia.co.uk/publication/kanojia-2014-pacman/","publishdate":"2019-06-27T12:40:43.63225Z","relpermalink":"/publication/kanojia-2014-pacman/","section":"publication","summary":"We present a Parallel Corpora Management tool that aides parallel corpora generation for the task of Machine Translation (MT). It takes source and target text of a corpus for any language pair in text file format, or zip archives containing multiple corresponding text files. Then, it provides with a helpful interface to lexicographers for manual translation / validation, and gives out the corrected text files as output. It provides various dictionary references as help within the interface which increase the productivity and efficiency of a lexicographer. It also provides automatic translation of the source sentence using an integrated MT system. The tool interface includes a corpora management system which facilitates maintenance of parallel corpora by assigning roles such as manager, lexicographer etc. We have designed a novel tool that provides aides like references to various dictionary sources such as Wordnets, Shabdkosh, Wikitionary etc. We also provide manual word alignment correction which is visualized in the tool and can lead to its gamification in the future, thus, providing a valuable source of word / phrase alignments.","tags":["machine translation","corpus management","application"],"title":"PaCMan: Parallel Corpus Management Workbench","type":"publication"},{"authors":["Neha R Prabhugaonkar","Apurva S Nagvenkar","Diptesh Kanojia","Jyoti D. Pawar","Pushpak Bhattacharyya","Manish Shrivastava"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"14afd32d7d582d2abf7b2f5a21261a3c","permalink":"https://dipteshkanojia.co.uk/publication/prabhugaonkar-2014-panchbhoota/","publishdate":"2019-06-27T12:40:43.632478Z","relpermalink":"/publication/prabhugaonkar-2014-panchbhoota/","section":"publication","summary":"We present our work on developing fifteen Hierarchical Phrase Based Statistical Machine Translation (HPBSMT) systems for five Indian language pairs namely Bengali-Hindi, English-Hindi, Marathi-Hindi, Tamil-Hindi, and Telugu-Hindi, in three domains each, HEALTH, TOURISM and GENERAL. We named them PanchBhoota, as these systems are elemental in nature. We used a very simple approach to train, tune, and test them using 'cdec' toolkit. We hope that this work will motivate Indian Language Machine Translation researchers to look deeper into the field of HPBSMT which is known to perform better than Phrase Based Statistical Machine Translation","tags":["winner","machine translation","linguistics","shared task","competition"],"title":"PanchBhoota: Hierarchical phrase based machine translation systems for five Indian languages","type":"publication"},{"authors":["Salil Joshi","Diptesh Kanojia","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"d666c7337ff369f3e55a383f15eeedda","permalink":"https://dipteshkanojia.co.uk/publication/joshi-2013-more/","publishdate":"2019-06-27T12:40:43.631473Z","relpermalink":"/publication/joshi-2013-more/","section":"publication","summary":"Word Sense Disambiguation (WSD) approaches have reported good accuracies in recent years. However, these approaches can be classified as weak AI systems. According to the classical definition, a strong AI based WSD system should perform the task of sense disambiguation in the same manner and with similar accuracy as human beings. In order to accomplish this, a detailed understanding of the human techniques employed for sense disambiguation is necessary. Instead of building yet another WSD system that uses contextual evidence for sense disambiguation, as has been done before, we have taken a step back - we have endeavored to discover the cognitive faculties that lie at the very core of the human sense disambiguation technique. In this paper, we present a hypothesis regarding the cognitive sub-processes involved in the task of WSD. We support our hypothesis using the experiments conducted through the means of an eye-tracking device. We also strive to find the levels of difficulties in annotating various classes of words, with senses. We believe, once such an in-depth analysis is performed, numerous insights can be gained to develop a robust WSD system that conforms to the principle of strong AI.","tags":["gaze tracking","word sense disambiguation","theoretical"],"title":"More than meets the eye: Study of Human Cognition in Sense Annotation","type":"publication"},{"authors":["Arindam Chatterjee","Salil Joshi","Pushpak Bhattacharyya","Diptesh Kanojia","Akhlesh Kumar Meena"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"cb5f13494aed36490a8f152e07b74d5d","permalink":"https://dipteshkanojia.co.uk/publication/chatterjee-2012-study/","publishdate":"2019-06-27T12:40:43.631013Z","relpermalink":"/publication/chatterjee-2012-study/","section":"publication","summary":"Does context help determine sense? This question might seem frivolous, even preposterous to anybody sensible. However, our long time research on Word Sense Disambiguation (WSD) shows that in almost all disambiguation algorithms, the sense distribution parameter P(S/W), where P is the probability of the sense of a word W being S, plays the deciding role. The widely reported accuracy figure of around 60% for all-words-domain-independent WSD is contributed to mainly by P(S/W), as one ablation test after another reveals. The story with human annotation is different though. Our experience of working with human annotators who mark with WordNet sense ids, general and domain specific corpora brings to light the interesting fact that producing sense ids without looking at the context is a heavy cognitive load. Sense annotators do form hypothesis in their minds about the possible sense of a word (‘most frequent sense’ bias), but then look at the context for clues to accept or reject the hypothesis. Such clues are minimal, just one or two words, but are critical nonetheless. Without these clues the annotator is left in an indecisive state as to whether or not to put down the first sense coming to his mind. The task becomes all the more cognitively challenging, if the senses are fine grained and seem equally probable. These facts increase the annotation time by a factor of almost 1.5. In the current paper we explore the dichotomy that might exist between machines and humans in the way they determine senses. We study the various parameters for WSD and also the sense marking behavior of human sense annotators. The observations, though not completely conclusive, establish the need for context for humans and that for accurate sense distribution parameters for machines.","tags":["word sense disambiguation","theoretical"],"title":"A Study of the Sense Annotation Process: Man v/s Machine.","type":"publication"},{"authors":["Diptesh Kanojia","Arindam Chatterjee","Salil Joshi","Pushpak Bhattacharyya"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"90073a90cba2d3992fee7ae2988160f3","permalink":"https://dipteshkanojia.co.uk/publication/kanojia-2012-discrimination/","publishdate":"2019-06-27T12:40:43.632706Z","relpermalink":"/publication/kanojia-2012-discrimination/","section":"publication","summary":"Current state-of-the-art Word Sense Disambiguation (WSD) algorithms are mostly supervised and use the P (Sense|Word) statistic for annotation. This P (Sense|Word) statistic is obtained after training the model on an annotated corpus. The performance of WSD algorithms do not match the efficiency and quality of human annotation. It is therefore important to know the role of the contextual clues in WSD. Human beings in turn, actuate the task of disambiguating the sense of a word, by gathering hints from the context words in the neighbourhood of the word. Contextual clues thus form the basic building block for the human sense disambiguation task. The need was thus felt for a tool, which could help us get a deeper insight into the human mind, while disambiguating polysemous words. As mentioned earlier, in the human mind, sense disambiguation highly depends on finding clues in corpus text, which finally lead to a winner sense. In order to make WSD algorithms more efficient, it is highly desirable to assimilate knowledge regarding contextual clues of words. In order to make WSD algorithms more efficient, it is highly desirable to assimilate knowledge regarding contextual clues of words, which aid in finding correct senses of words in that context. Hence, we developed a tool which could help a lexicographer mark the clues for disambiguating a word in a context. In the current phase, this tool lets the lexicographer select the clues from the gloss and example fields in the synset, and adds them to a database.","tags":["word sense disambiguation","applciation","linguistics"],"title":"Discrimination-net for Hindi","type":"publication"}]